% ============================================================
% CHƯƠNG BỔ SUNG: CÔNG VIỆC THỰC HIỆN TRÊN PROJECT
% Thêm vào sau Chapter 9 (trước Conclusion)
% ============================================================

% ============================================================
% CHAPTER 10: IMPLEMENTATION - PROJECT MODIFICATIONS
% ============================================================
\chapter{Triển khai thực nghiệm: Cải tiến và hiện đại hoá codebase}

Chương này trình bày chi tiết các thay đổi đã thực hiện trên codebase gốc từ repository \texttt{Aviral-03/ViT-Chest-Xray} \cite{aviralrepo} nhằm: (i) đảm bảo tương thích với môi trường Python hiện đại, (ii) chuẩn hoá pipeline dữ liệu, (iii) sửa lỗi tính toán metric, và (iv) tạo nền tảng cho nghiên cứu tái lập.

\section{Tổng quan thay đổi so với bản gốc}

\subsection{Vấn đề với codebase gốc}
Repository gốc \cite{aviralrepo} sử dụng TensorFlow/Keras làm framework chính. Tuy nhiên, trong quá trình triển khai, chúng tôi gặp phải các vấn đề sau:

\begin{enumerate}
  \item \textbf{Tương thích phiên bản Python:} TensorFlow chưa hỗ trợ Python 3.13+, gây lỗi \texttt{ModuleNotFoundError: No module named 'tensorflow'}.
  \item \textbf{Thiếu nhất quán data pipeline:} Mỗi notebook có cách load dữ liệu riêng, gây khó khăn trong việc so sánh công bằng giữa các mô hình.
  \item \textbf{Đường dẫn hardcoded:} Các đường dẫn được viết cứng theo macOS/Linux, không tương thích Windows.
  \item \textbf{Lỗi tính AUC:} Sklearn \texttt{roc\_auc\_score} trả về NaN khi một số class không có đủ mẫu positive/negative.
\end{enumerate}

\subsection{Giải pháp tổng thể: Migration sang PyTorch}
Chúng tôi quyết định chuyển toàn bộ codebase sang PyTorch vì:
\begin{itemize}
  \item PyTorch tương thích tốt với Python 3.13+
  \item Hiệu suất cao cho Vision Transformers (dynamic computation graph)
  \item Hệ sinh thái phong phú: thư viện \texttt{timm} cung cấp nhiều pre-trained ViT models
  \item Dễ debug và custom hơn so với TensorFlow graph mode
\end{itemize}

\section{Chi tiết các thay đổi kỹ thuật}

\subsection{Thay đổi 1: Chuẩn hoá cấu hình đường dẫn}
\label{sec:config}

Tạo file \texttt{config.py} tập trung quản lý cấu hình:

\begin{lstlisting}[language=Python,caption={config.py - Cấu hình tập trung cho project.}]
import os

def get_project_root():
    """Get the root directory of the project."""
    current_dir = os.path.dirname(os.path.abspath(__file__))
    if os.path.basename(current_dir) == "Project":
        return os.path.dirname(current_dir)
    return current_dir

PROJECT_ROOT = get_project_root()

# Data paths
DATA_ROOT = os.path.join(PROJECT_ROOT, "Project", "input")
IMAGES_DIR = os.path.join(DATA_ROOT, "images")
LABELS_CSV = os.path.join(DATA_ROOT, "Data_Entry_2017_v2020.csv")

# Model settings
IMAGE_SIZE = 224
BATCH_SIZE = 32
NUM_CLASSES = 15
LABELS = [
    'Cardiomegaly', 'Emphysema', 'Effusion',
    'Hernia', 'Nodule', 'Pneumothorax', 'Atelectasis',
    'Pleural_Thickening', 'Mass', 'Edema', 'Consolidation',
    'Infiltration', 'Fibrosis', 'Pneumonia', 'No Finding'
]
\end{lstlisting}

\textbf{Lợi ích:}
\begin{itemize}
  \item Cross-platform: hoạt động trên Windows, macOS, Linux
  \item Single source of truth: thay đổi một nơi, áp dụng toàn project
  \item Dễ bảo trì và mở rộng
\end{itemize}

\subsection{Thay đổi 2: Chuyển Data Pipeline sang PyTorch}
\label{sec:data_pipeline}

\subsubsection{Cũ: TensorFlow ImageDataGenerator}
\begin{lstlisting}[language=Python,caption={Data pipeline gốc (TensorFlow/Keras).}]
# Original code (TensorFlow)
from tensorflow.keras.preprocessing.image import ImageDataGenerator

train_datagen = ImageDataGenerator(
    rescale=1./255,
    horizontal_flip=True,
    rotation_range=5
)
train_generator = train_datagen.flow_from_dataframe(
    dataframe=train_df,
    directory=images_path,
    ...
)
\end{lstlisting}

\subsubsection{Mới: PyTorch Dataset và DataLoader}
\begin{lstlisting}[language=Python,caption={Data pipeline mới (PyTorch).}]
# New code (PyTorch)
import torch
from torch.utils.data import Dataset, DataLoader
from torchvision import transforms

class ChestXrayDataset(Dataset):
    def __init__(self, dataframe, images_path, labels, transform=None):
        self.dataframe = dataframe.reset_index(drop=True)
        self.images_path = images_path
        self.labels = labels
        self.transform = transform
        
    def __len__(self):
        return len(self.dataframe)
    
    def __getitem__(self, idx):
        img_name = self.dataframe.iloc[idx]['Image Index']
        img_path = os.path.join(self.images_path, img_name)
        image = Image.open(img_path).convert('RGB')
        
        if self.transform:
            image = self.transform(image)
        
        label = torch.tensor(
            self.dataframe.iloc[idx][self.labels].values.astype(float),
            dtype=torch.float32
        )
        return image, label

# Transforms
train_transform = transforms.Compose([
    transforms.Resize((224, 224)),
    transforms.RandomHorizontalFlip(p=0.5),
    transforms.RandomRotation(degrees=5),
    transforms.ColorJitter(brightness=0.1, contrast=0.1),
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.485, 0.456, 0.406], 
                        std=[0.229, 0.224, 0.225])
])

# DataLoaders
train_loader = DataLoader(train_dataset, batch_size=32, 
                         shuffle=True, num_workers=0)
val_loader = DataLoader(val_dataset, batch_size=32, 
                       shuffle=False, num_workers=0)
\end{lstlisting}

\textbf{So sánh:}
\begin{table}[H]
\centering
\caption{So sánh Data Pipeline TensorFlow vs PyTorch.}
\begin{tabular}{@{}lll@{}}
\toprule
\textbf{Aspect} & \textbf{TensorFlow (Gốc)} & \textbf{PyTorch (Mới)} \\
\midrule
Data loading & ImageDataGenerator & Custom Dataset class \\
Augmentation & Built-in generators & torchvision.transforms \\
Batch loading & flow\_from\_dataframe & DataLoader \\
Flexibility & Limited & High (custom \_\_getitem\_\_) \\
Debugging & Difficult (graph mode) & Easy (eager mode) \\
\bottomrule
\end{tabular}
\end{table}

\subsection{Thay đổi 3: Sửa lỗi AUC NaN}
\label{sec:auc_fix}

\subsubsection{Nguyên nhân lỗi}
Hàm \texttt{sklearn.metrics.roc\_auc\_score} với \texttt{average='macro'} yêu cầu mỗi class phải có \textbf{ít nhất 1 mẫu positive (1)} và \textbf{ít nhất 1 mẫu negative (0)}. Trong bài toán multi-label với 15 classes và dữ liệu mất cân bằng, điều kiện này thường không thoả mãn, đặc biệt với batch nhỏ.

\subsubsection{So sánh hành vi Keras vs Sklearn}
\begin{table}[H]
\centering
\caption{So sánh cách tính AUC giữa Keras và Sklearn.}
\begin{tabular}{@{}lll@{}}
\toprule
\textbf{Aspect} & \textbf{Keras AUC metric} & \textbf{Sklearn roc\_auc\_score} \\
\midrule
Edge case handling & Tự động (trả về 0) & Cần xử lý thủ công \\
Khi class chỉ có 0 & Bỏ qua, không lỗi & Trả về NaN hoặc Error \\
Tích hợp & Có sẵn trong compile() & Phải tính riêng \\
\bottomrule
\end{tabular}
\end{table}

\subsubsection{Giải pháp}
\begin{lstlisting}[language=Python,caption={Fix AUC NaN - chỉ tính cho các class hợp lệ.}]
def calculate_auc_safe(targets, outputs):
    """Calculate AUC only for classes with both 0 and 1 samples."""
    try:
        # Find classes with both positive and negative samples
        valid_classes = []
        for i in range(targets.shape[1]):
            if len(np.unique(targets[:, i])) > 1:
                valid_classes.append(i)
        
        if len(valid_classes) > 0:
            auc = roc_auc_score(
                targets[:, valid_classes], 
                outputs[:, valid_classes], 
                average='macro'
            )
        else:
            auc = 0.0
    except ValueError:
        auc = 0.0
    return auc
\end{lstlisting}

\subsection{Thay đổi 4: Chuyển CNN sang PyTorch}
\label{sec:cnn_migration}

\subsubsection{Kiến trúc CNN baseline}
\begin{lstlisting}[language=Python,caption={CNN baseline với PyTorch.}]
class CNNClassifier(nn.Module):
    def __init__(self, num_classes=15):
        super(CNNClassifier, self).__init__()
        self.features = nn.Sequential(
            # Block 1
            nn.Conv2d(3, 32, kernel_size=3, padding=1),
            nn.ReLU(inplace=True),
            nn.MaxPool2d(kernel_size=2, stride=2),
            # Block 2
            nn.Conv2d(32, 64, kernel_size=3, padding=1),
            nn.ReLU(inplace=True),
            nn.MaxPool2d(kernel_size=2, stride=2),
        )
        self.classifier = nn.Sequential(
            nn.Flatten(),
            nn.Linear(64 * 56 * 56, 512),
            nn.ReLU(inplace=True),
            nn.Dropout(0.5),
            nn.Linear(512, num_classes),
        )
    
    def forward(self, x):
        x = self.features(x)
        x = self.classifier(x)
        return x  # Logits for BCEWithLogitsLoss
\end{lstlisting}

\subsection{Thay đổi 5: Chuyển ResNet-34 sang PyTorch}
\label{sec:resnet_migration}

\begin{lstlisting}[language=Python,caption={ResNet-34 với PyTorch.}]
class BasicBlock(nn.Module):
    expansion = 1
    
    def __init__(self, in_channels, out_channels, stride=1, downsample=None):
        super(BasicBlock, self).__init__()
        self.conv1 = nn.Conv2d(in_channels, out_channels, 
                               kernel_size=3, stride=stride, padding=1, bias=False)
        self.bn1 = nn.BatchNorm2d(out_channels)
        self.relu = nn.ReLU(inplace=True)
        self.conv2 = nn.Conv2d(out_channels, out_channels, 
                               kernel_size=3, stride=1, padding=1, bias=False)
        self.bn2 = nn.BatchNorm2d(out_channels)
        self.downsample = downsample
        
    def forward(self, x):
        identity = x
        out = self.conv1(x)
        out = self.bn1(out)
        out = self.relu(out)
        out = self.conv2(out)
        out = self.bn2(out)
        
        if self.downsample is not None:
            identity = self.downsample(x)
        
        out += identity  # Residual connection
        out = self.relu(out)
        return out

class ResNet(nn.Module):
    def __init__(self, block, layers, num_classes=15):
        super(ResNet, self).__init__()
        self.in_channels = 64
        # Initial convolution
        self.conv1 = nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3, bias=False)
        self.bn1 = nn.BatchNorm2d(64)
        self.relu = nn.ReLU(inplace=True)
        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)
        # ResNet layers
        self.layer1 = self._make_layer(block, 64, layers[0])
        self.layer2 = self._make_layer(block, 128, layers[1], stride=2)
        self.layer3 = self._make_layer(block, 256, layers[2], stride=2)
        self.layer4 = self._make_layer(block, 512, layers[3], stride=2)
        # Classifier
        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))
        self.fc = nn.Linear(512, num_classes)
        
def create_resnet34(num_classes=15):
    return ResNet(BasicBlock, [3, 4, 6, 3], num_classes=num_classes)
\end{lstlisting}

\subsection{Thay đổi 6: Chuyển Vision Transformer sang PyTorch}
\label{sec:vit_migration}

\begin{lstlisting}[language=Python,caption={Vision Transformer from scratch với PyTorch.}]
class PatchEmbedding(nn.Module):
    """Convert image to patch embeddings."""
    def __init__(self, img_size=224, patch_size=32, in_channels=3, embed_dim=64):
        super().__init__()
        self.num_patches = (img_size // patch_size) ** 2
        self.proj = nn.Conv2d(in_channels, embed_dim, 
                              kernel_size=patch_size, stride=patch_size)
    
    def forward(self, x):
        x = self.proj(x)  # (B, embed_dim, H/P, W/P)
        x = x.flatten(2)   # (B, embed_dim, num_patches)
        x = x.transpose(1, 2)  # (B, num_patches, embed_dim)
        return x

class TransformerEncoderBlock(nn.Module):
    """Standard Transformer encoder block."""
    def __init__(self, embed_dim, num_heads, mlp_ratio=4, dropout=0.1):
        super().__init__()
        self.ln1 = nn.LayerNorm(embed_dim)
        self.attn = nn.MultiheadAttention(embed_dim, num_heads, 
                                          dropout=dropout, batch_first=True)
        self.ln2 = nn.LayerNorm(embed_dim)
        self.mlp = nn.Sequential(
            nn.Linear(embed_dim, int(embed_dim * mlp_ratio)),
            nn.GELU(),
            nn.Dropout(dropout),
            nn.Linear(int(embed_dim * mlp_ratio), embed_dim),
            nn.Dropout(dropout),
        )
    
    def forward(self, x):
        # Self-attention with residual
        x_norm = self.ln1(x)
        attn_out, _ = self.attn(x_norm, x_norm, x_norm)
        x = x + attn_out
        # MLP with residual
        x = x + self.mlp(self.ln2(x))
        return x

class VisionTransformer(nn.Module):
    """Vision Transformer for multi-label classification."""
    def __init__(self, img_size=224, patch_size=32, in_channels=3,
                 num_classes=15, embed_dim=64, depth=4, num_heads=4,
                 mlp_ratio=4, dropout=0.1):
        super().__init__()
        self.patch_embed = PatchEmbedding(img_size, patch_size, in_channels, embed_dim)
        num_patches = self.patch_embed.num_patches
        
        # Learnable positional embedding
        self.pos_embed = nn.Parameter(torch.zeros(1, num_patches + 1, embed_dim))
        self.cls_token = nn.Parameter(torch.zeros(1, 1, embed_dim))
        self.pos_drop = nn.Dropout(dropout)
        
        # Transformer encoder blocks
        self.blocks = nn.ModuleList([
            TransformerEncoderBlock(embed_dim, num_heads, mlp_ratio, dropout)
            for _ in range(depth)
        ])
        
        self.norm = nn.LayerNorm(embed_dim)
        self.head = nn.Linear(embed_dim, num_classes)
    
    def forward(self, x):
        B = x.shape[0]
        x = self.patch_embed(x)
        
        # Add CLS token
        cls_tokens = self.cls_token.expand(B, -1, -1)
        x = torch.cat([cls_tokens, x], dim=1)
        
        # Add positional embedding
        x = x + self.pos_embed
        x = self.pos_drop(x)
        
        # Transformer blocks
        for block in self.blocks:
            x = block(x)
        
        x = self.norm(x)
        cls_output = x[:, 0]  # CLS token output
        return self.head(cls_output)
\end{lstlisting}

\subsection{Thay đổi 7: Cải tiến ViT-v2 với Early Stopping và LR Scheduler}

\begin{lstlisting}[language=Python,caption={ViT-v2 với Early Stopping và Learning Rate Scheduler.}]
from torch.optim.lr_scheduler import ReduceLROnPlateau

def train_model_v2(model, train_loader, val_loader, criterion, 
                   optimizer, num_epochs=10, patience=5):
    """Training với early stopping và learning rate scheduling."""
    
    scheduler = ReduceLROnPlateau(optimizer, mode='min', 
                                  factor=0.1, patience=5, min_lr=1e-6)
    
    best_val_loss = float('inf')
    patience_counter = 0
    history = {'train_loss': [], 'val_loss': [], 'train_auc': [], 
               'val_auc': [], 'lr': []}
    
    for epoch in range(num_epochs):
        # Training phase
        model.train()
        # ... training loop ...
        
        # Validation phase
        model.eval()
        # ... validation loop ...
        
        # Learning rate scheduling
        scheduler.step(epoch_val_loss)
        
        # Early stopping check
        if epoch_val_loss < best_val_loss:
            best_val_loss = epoch_val_loss
            patience_counter = 0
            torch.save(model.state_dict(), 'best_model.pth')
        else:
            patience_counter += 1
            if patience_counter >= patience:
                print(f'Early stopping at epoch {epoch+1}')
                break
        
        # Log current learning rate
        current_lr = optimizer.param_groups[0]['lr']
        history['lr'].append(current_lr)
    
    return history
\end{lstlisting}

\textbf{Lưu ý:} PyTorch 2.10+ đã loại bỏ tham số \texttt{verbose} trong \texttt{ReduceLROnPlateau}. Code đã được cập nhật để tương thích.

\subsection{Thay đổi 8: Cập nhật ViT-ResNet (Pre-trained)}

Notebook \texttt{ViT-ResNet.ipynb} đã được cập nhật để:
\begin{enumerate}
  \item Sử dụng chung \texttt{data.ipynb} thay vì data loading riêng
  \item Áp dụng AUC fix
  \item Sử dụng pre-trained ViT từ thư viện \texttt{timm}
\end{enumerate}

\begin{lstlisting}[language=Python,caption={Pre-trained ViT với timm library.}]
import timm

# Load pre-trained ViT
model = timm.create_model('vit_base_patch16_224', pretrained=True)

# Replace classification head for 15 classes
num_classes = 15
model.head = nn.Linear(model.head.in_features, num_classes)
model.to(device)

# Loss and optimizer
criterion = nn.BCEWithLogitsLoss()
optimizer = Adam(model.parameters(), lr=1e-4)
\end{lstlisting}

\section{Tổng hợp các thay đổi}

\begin{table}[H]
\centering
\caption{Tổng hợp các thay đổi trên từng notebook.}
\label{tab:changes_summary}
\begin{tabular}{@{}p{2.5cm}p{3cm}p{3.5cm}p{4cm}@{}}
\toprule
\textbf{Notebook} & \textbf{Trạng thái gốc} & \textbf{Thay đổi} & \textbf{Trạng thái mới} \\
\midrule
\texttt{data.ipynb} & TensorFlow ImageDataGenerator & $\rightarrow$ PyTorch Dataset/DataLoader & PyTorch DataLoaders \\
\texttt{cnn.ipynb} & TensorFlow/Keras & $\rightarrow$ PyTorch + AUC fix & PyTorch CNN \\
\texttt{resnet.ipynb} & TensorFlow/Keras & $\rightarrow$ PyTorch + AUC fix & PyTorch ResNet-34 \\
\texttt{ViT-v1.ipynb} & TensorFlow/Keras & $\rightarrow$ PyTorch + AUC fix & PyTorch ViT from scratch \\
\texttt{ViT-v2.ipynb} & TensorFlow/Keras & $\rightarrow$ PyTorch + AUC fix + LR fix & PyTorch ViT v2 \\
\texttt{ViT-ResNet.ipynb} & PyTorch (data riêng) & $\rightarrow$ Dùng data.ipynb + AUC fix & Pre-trained ViT (timm) \\
\bottomrule
\end{tabular}
\end{table}

\section{Kết quả thực nghiệm}

\subsection{Môi trường thực nghiệm}
\begin{itemize}
  \item \textbf{Python}: 3.13.7
  \item \textbf{PyTorch}: 2.10.0+cu126
  \item \textbf{GPU}: NVIDIA GeForce RTX 3060 Laptop GPU
  \item \textbf{CUDA}: 12.6
  \item \textbf{RAM}: 16GB
\end{itemize}

\subsection{Kết quả training}

\begin{table}[H]
\centering
\caption{Kết quả thực nghiệm trên tập test (dataset nhỏ: 60 train / 20 val / 20 test).}
\label{tab:experiment_results}
\begin{tabular}{@{}lcccc@{}}
\toprule
\textbf{Mô hình} & \textbf{Parameters} & \textbf{Test Acc (\%)} & \textbf{Test AUC} & \textbf{Ghi chú} \\
\midrule
ViT-v1 (from scratch) & $\sim$9M & \textbf{91.33} & 0.5854 & Accuracy cao nhất \\
ViT-v2 (with early stopping) & $\sim$9M & 89.67 & 0.6303 & - \\
Pre-trained ViT (timm) & $\sim$86M & 87.00 & \textbf{0.6694} & AUC cao nhất \\
\bottomrule
\end{tabular}
\end{table}

\textbf{Lưu ý quan trọng:} Dataset thực nghiệm rất nhỏ (chỉ 60 training samples), do đó kết quả chưa đáng tin cậy để đánh giá hiệu năng thực sự của các mô hình. Cần tăng kích thước dataset để có đánh giá chính xác hơn.

\subsection{Phân tích kết quả}

\begin{enumerate}
  \item \textbf{ViT-v1 đạt accuracy cao nhất (91.33\%):} Có thể do model nhỏ hơn (9M params) fit tốt với dataset nhỏ, tránh overfitting.
  
  \item \textbf{Pre-trained ViT đạt AUC cao nhất (0.6694):} Mặc dù accuracy thấp hơn, AUC cao hơn cho thấy model này có khả năng phân biệt tốt hơn giữa các class, đặc biệt với class hiếm.
  
  \item \textbf{Trade-off accuracy vs AUC:} Kết quả phù hợp với phân tích trong paper về việc accuracy có thể bị chi phối bởi class phổ biến (``No Finding''), trong khi AUC phản ánh tốt hơn khả năng phân loại đa nhãn.
\end{enumerate}

\section{Lịch sử commit}

\begin{table}[H]
\centering
\caption{Lịch sử các commit chính trong quá trình cải tiến.}
\begin{tabular}{@{}lp{3cm}p{7cm}@{}}
\toprule
\textbf{Commit} & \textbf{Ngày} & \textbf{Mô tả} \\
\midrule
\texttt{15e684e} & 30/01/2026 & Refactor path configs for cross-platform + add config.py \\
\texttt{7aa8947} & 31/01/2026 & Migrate from TensorFlow to PyTorch for Python 3.14 compatibility \\
\texttt{b36824c} & 01/02/2026 & Migrate all notebooks to PyTorch + Fix AUC NaN + Training results \\
\bottomrule
\end{tabular}
\end{table}

\section{Hướng dẫn chạy project đã cải tiến}

\subsection{Yêu cầu môi trường}
\begin{lstlisting}[language=bash,caption={Cài đặt môi trường.}]
# Tạo virtual environment với Python 3.13+
python -m venv .venv313
.venv313\Scripts\activate  # Windows
# source .venv313/bin/activate  # Linux/macOS

# Cài đặt dependencies
pip install -r requirements.txt
\end{lstlisting}

\subsection{Thứ tự chạy notebooks}
\begin{enumerate}
  \item \textbf{data.ipynb}: Load và chuẩn bị dữ liệu (bắt buộc chạy trước)
  \item Sau đó chạy bất kỳ model notebook nào:
  \begin{itemize}
    \item \texttt{cnn.ipynb}: CNN baseline
    \item \texttt{resnet.ipynb}: ResNet-34
    \item \texttt{ViT-v1.ipynb}: Vision Transformer from scratch
    \item \texttt{ViT-v2.ipynb}: ViT với early stopping
    \item \texttt{ViT-ResNet.ipynb}: Pre-trained ViT
  \end{itemize}
\end{enumerate}

\section{Đóng góp so với bản gốc}

\begin{enumerate}
  \item \textbf{Hiện đại hoá framework:} Chuyển từ TensorFlow sang PyTorch, đảm bảo tương thích với Python 3.13+
  
  \item \textbf{Chuẩn hoá pipeline:} Tất cả notebooks sử dụng chung \texttt{data.ipynb}, đảm bảo so sánh công bằng
  
  \item \textbf{Cross-platform:} Thêm \texttt{config.py} để hoạt động trên mọi hệ điều hành
  
  \item \textbf{Bug fix:} Sửa lỗi AUC NaN, fix ReduceLROnPlateau verbose error
  
  \item \textbf{Tài liệu:} Thêm file \texttt{BAO\_CAO\_THAY\_DOI.md} ghi lại chi tiết mọi thay đổi
  
  \item \textbf{Reproducibility:} Fixed seed, log versions, commit history rõ ràng
\end{enumerate}

% ============================================================
% END OF SUPPLEMENTARY CHAPTER
% ============================================================
