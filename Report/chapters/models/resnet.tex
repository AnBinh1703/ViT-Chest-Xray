% ============================================================================
% MÔ HÌNH RESNET-34
% ============================================================================
\section{Mô hình ResNet-34}
\label{sec:resnet_model}

\subsection{Kiến trúc mô hình}

Mô hình ResNet-34 được xây dựng từ đầu (from scratch) theo kiến trúc gốc của He et al. (2016). Đặc điểm quan trọng nhất của ResNet là \textbf{skip connections} (residual connections), cho phép gradient lan truyền trực tiếp qua nhiều lớp, giải quyết vấn đề vanishing gradient trong các mạng sâu.

\textbf{Cấu trúc BasicBlock:}
\begin{itemize}[noitemsep]
    \item Conv2d ($3 \times 3$) $\rightarrow$ BatchNorm2d $\rightarrow$ ReLU
    \item Conv2d ($3 \times 3$) $\rightarrow$ BatchNorm2d
    \item Skip connection: $output = F(x) + x$
    \item ReLU activation cuối cùng
\end{itemize}

\textbf{Cấu hình ResNet-34:}
\begin{table}[H]
\centering
\caption{Cấu hình các layer trong ResNet-34}
\label{tab:resnet_layers}
\begin{tabular}{lcccc}
\toprule
\textbf{Layer} & \textbf{Channels} & \textbf{Blocks} & \textbf{Stride} & \textbf{Output Size} \\
\midrule
Conv1 (7$\times$7) & 64 & -- & 2 & $112 \times 112$ \\
MaxPool & 64 & -- & 2 & $56 \times 56$ \\
Layer1 & 64 & 3 & 1 & $56 \times 56$ \\
Layer2 & 128 & 4 & 2 & $28 \times 28$ \\
Layer3 & 256 & 6 & 2 & $14 \times 14$ \\
Layer4 & 512 & 3 & 2 & $7 \times 7$ \\
AvgPool & 512 & -- & -- & $1 \times 1$ \\
FC & 15 & -- & -- & 15 classes \\
\bottomrule
\end{tabular}
\end{table}

\textbf{Tổng số tham số:} $\sim$21 triệu tham số

\textbf{Ưu điểm so với CNN baseline:}
\begin{itemize}[noitemsep]
    \item Sử dụng \textbf{Global Average Pooling} thay vì Flatten $\Rightarrow$ giảm đáng kể số tham số
    \item \textbf{Batch Normalization} ổn định quá trình huấn luyện
    \item \textbf{Skip connections} giúp huấn luyện mạng sâu hiệu quả hơn
    \item \textbf{Kaiming initialization} cho các lớp tích chập
\end{itemize}

\subsection{Cấu hình huấn luyện}

\begin{table}[H]
\centering
\caption{Cấu hình huấn luyện mô hình ResNet-34}
\label{tab:resnet_config}
\begin{tabular}{ll}
\toprule
\textbf{Tham số} & \textbf{Giá trị} \\
\midrule
Kích thước ảnh & $224 \times 224$ \\
Batch Size & 32 \\
Learning Rate & $1 \times 10^{-4}$ \\
Weight Decay & $1 \times 10^{-6}$ \\
Số Epoch & 10 \\
Optimizer & AdamW \\
Loss Function & BCEWithLogitsLoss \\
Weight Initialization & Kaiming Normal \\
\bottomrule
\end{tabular}
\end{table}

\subsection{Kết quả thực nghiệm}

\begin{table}[H]
\centering
\caption{Kết quả huấn luyện mô hình ResNet-34 (10 epoch)}
\label{tab:resnet_results}
\begin{tabular}{lccc}
\toprule
\textbf{Chỉ số} & \textbf{Train} & \textbf{Validation} & \textbf{Test} \\
\midrule
Loss (epoch cuối) & 0.2786 & 0.3742 & -- \\
AUC (epoch cuối) & 0.7768 & 0.5235 & $\sim$0.53 \\
Best Val AUC & -- & 0.5293 (epoch 6) & -- \\
\bottomrule
\end{tabular}
\end{table}

\textbf{Nhận xét:}
\begin{itemize}[noitemsep]
    \item \textbf{Hiệu suất thấp hơn kỳ vọng}: Val AUC chỉ đạt 0.53, thấp hơn CNN baseline (0.60).
    \item \textbf{Vẫn có overfitting}: Train AUC (0.78) cao hơn nhiều so với Val AUC (0.52).
    \item \textbf{Nguyên nhân có thể}: 
    \begin{itemize}
        \item Mô hình huấn luyện từ đầu cần nhiều dữ liệu hơn
        \item Không sử dụng pretrained weights từ ImageNet
        \item Số mẫu huấn luyện nhỏ (100 ảnh sample)
    \end{itemize}
\end{itemize}

\textbf{So sánh với CNN:}
\begin{itemize}[noitemsep]
    \item ResNet-34 có ít tham số hơn nhiều (21M vs 95M)
    \item Tuy nhiên, với lượng dữ liệu nhỏ, mô hình đơn giản như CNN lại cho kết quả tốt hơn
    \item Điều này gợi ý rằng cần sử dụng transfer learning cho các mô hình sâu
\end{itemize}

\subsection{Đoạn mã minh họa}

\begin{lstlisting}[language=Python, caption=Định nghĩa BasicBlock và hàm \_make\_layer]
class BasicBlock(nn.Module):
    expansion = 1
    
    def __init__(self, in_channels, out_channels, stride=1, downsample=None):
        super(BasicBlock, self).__init__()
        self.conv1 = nn.Conv2d(in_channels, out_channels, 
                               kernel_size=3, stride=stride, padding=1, bias=False)
        self.bn1 = nn.BatchNorm2d(out_channels)
        self.relu = nn.ReLU(inplace=True)
        self.conv2 = nn.Conv2d(out_channels, out_channels, 
                               kernel_size=3, stride=1, padding=1, bias=False)
        self.bn2 = nn.BatchNorm2d(out_channels)
        self.downsample = downsample
        
    def forward(self, x):
        identity = x
        
        out = self.conv1(x)
        out = self.bn1(out)
        out = self.relu(out)
        out = self.conv2(out)
        out = self.bn2(out)
        
        if self.downsample is not None:
            identity = self.downsample(x)
        
        out += identity  # Skip connection
        out = self.relu(out)
        return out

def create_resnet34(num_classes=15):
    """Tao mo hinh ResNet-34 voi cau hinh [3,4,6,3] blocks"""
    return ResNet(BasicBlock, [3, 4, 6, 3], num_classes=num_classes)
\end{lstlisting}
