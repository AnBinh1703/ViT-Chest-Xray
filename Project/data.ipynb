{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Processing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "import random\n",
    "import math\n",
    "import warnings\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "# import tensorflow as tf  # Commented out - not compatible with Python 3.14\n",
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# For data augmentation and preprocessing, we'll use torchvision instead of Keras\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DatasetParser():\n",
    "    def __init__(self, root_dir, images_dir, labels_csv):\n",
    "        self.image_paths = sorted(glob.glob(os.path.join(root_dir, images_dir,\"*.png\")))\n",
    "        self.labels_df = self._labels_by_task(root_dir=root_dir, labels_csv=labels_csv, images_dir=images_dir)\n",
    "        \n",
    "        self.labels = ['Cardiomegaly','Emphysema','Effusion',\n",
    "                           'Hernia','Nodule','Pneumothorax','Atelectasis',\n",
    "                           'Pleural_Thickening','Mass','Edema','Consolidation',\n",
    "                           'Infiltration','Fibrosis','Pneumonia', 'No Finding']\n",
    "    \n",
    "    def visualize_random_images(self, num_images=1, label=None, display_label=False):\n",
    "        fig = plt.figure(figsize=(20,20))\n",
    "        fig.tight_layout(pad=10.0)\n",
    "        if label is None:\n",
    "            idxs = random.sample(range(len(self.image_paths)), num_images)\n",
    "        else:\n",
    "            idxs = [idx for idx in range(len(self.labels_df['Label'])) if label in self.labels_df['Label'][idx]]\n",
    "            if len(idxs) < num_images:\n",
    "                num_images = len(idxs)\n",
    "            else:\n",
    "                idxs = random.sample(idxs, num_images)\n",
    "                \n",
    "        num_rows = math.ceil(np.sqrt(num_images))\n",
    "        num_cols = math.ceil(num_images/num_rows)\n",
    "        \n",
    "        for i in range(num_images):\n",
    "            img = cv2.imread(self.image_paths[idxs[i]])\n",
    "            plt.subplot(num_rows, num_cols, i+1)\n",
    "            if display_label:\n",
    "                plt.gca().set_title(self.labels_df['Label'][idxs[i]],wrap=True)\n",
    "            plt.axis('off')\n",
    "            plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
    "    \n",
    "    def _labels_by_task(self, root_dir=None, labels_csv=None, images_dir=\".\"):\n",
    "        labels_df = pd.read_csv(os.path.join(root_dir, labels_csv))\n",
    "        \n",
    "        # Create image path mapping - handle both current dir and subdirectory cases\n",
    "        if images_dir == \".\":\n",
    "            image_paths = glob.glob(os.path.join(root_dir, '*.png'))\n",
    "        else:\n",
    "            image_paths = glob.glob(os.path.join(root_dir, images_dir, '*.png'))\n",
    "        \n",
    "        image_path = {os.path.basename(x): x for x in image_paths}\n",
    "        \n",
    "        labels_df = labels_df[labels_df['Image Index'].map(os.path.basename).isin(image_path)]\n",
    "\n",
    "        new_labels_df = pd.DataFrame()\n",
    "        new_labels_df['Id'] = labels_df['Image Index'].copy()\n",
    "        \n",
    "        new_labels_df['Label'] = labels_df['Finding Labels'].apply(lambda val: val.split('|'))\n",
    "        \n",
    "        del labels_df\n",
    "        \n",
    "        return new_labels_df\n",
    "        \n",
    "    def get_labels_df(self):\n",
    "        new_labels_df = self.labels_df.copy()\n",
    "        \n",
    "        for i in range(len(new_labels_df)):\n",
    "                one_hot = [0 for element in self.labels]\n",
    "                for element in new_labels_df['Label'][i]:\n",
    "                    one_hot[self.labels.index(element)] = 1\n",
    "                new_labels_df['Label'][i] = one_hot\n",
    "                \n",
    "        return new_labels_df\n",
    "    \n",
    "    def sample(self, num_samples, is_weighted=False):\n",
    "        if not is_weighted:\n",
    "            return self.labels_df.sample(num_samples)\n",
    "        else:\n",
    "            sample_weights = self.labels_df['Label'].map(lambda x: len(x)).values + 4e-2\n",
    "            sample_weights /= sample_weights.sum()\n",
    "            return self.labels_df.sample(num_samples, weights=sample_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data root: d:\\MSE\\10.Deep Learning\\Group_Final\\ViT-Chest-Xray\\Project\\input\n",
      "Total Trainable Data:  112120\n"
     ]
    }
   ],
   "source": [
    "# Use relative paths for Windows compatibility\n",
    "import os\n",
    "\n",
    "# Get the project root directory (parent of 'Project' folder)\n",
    "PROJECT_ROOT = os.path.dirname(os.path.dirname(os.path.abspath(__file__))) if '__file__' in dir() else os.path.dirname(os.getcwd())\n",
    "# For notebook execution, use current working directory approach\n",
    "PROJECT_ROOT = os.path.abspath(os.path.join(os.getcwd(), \"..\")) if os.path.basename(os.getcwd()) == \"Project\" else os.getcwd()\n",
    "\n",
    "# Configure paths - update these to match your data location\n",
    "ROOT_DIR = os.path.join(PROJECT_ROOT, \"Project\", \"input\")\n",
    "# Images are directly in the input folder, not in a subdirectory\n",
    "IMAGES_DIR = \".\"  # Changed from \"images\" to \".\" since images are in the root input dir\n",
    "LABELS_CSV = \"Data_Entry_2017_v2020.csv\"\n",
    "\n",
    "parser = DatasetParser(root_dir=ROOT_DIR,\n",
    "                       images_dir=IMAGES_DIR,\n",
    "                       labels_csv=LABELS_CSV)\n",
    "print(\"Data root:\", ROOT_DIR)\n",
    "print(\"Total Trainable Data: \", parser.labels_df.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5605</th>\n",
       "      <td>00001504_012.png</td>\n",
       "      <td>[Pleural_Thickening]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106005</th>\n",
       "      <td>00028526_000.png</td>\n",
       "      <td>[Infiltration]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11933</th>\n",
       "      <td>00003109_012.png</td>\n",
       "      <td>[No Finding]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100783</th>\n",
       "      <td>00026768_000.png</td>\n",
       "      <td>[No Finding]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34991</th>\n",
       "      <td>00009231_009.png</td>\n",
       "      <td>[No Finding]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Id                 Label\n",
       "5605    00001504_012.png  [Pleural_Thickening]\n",
       "106005  00028526_000.png        [Infiltration]\n",
       "11933   00003109_012.png          [No Finding]\n",
       "100783  00026768_000.png          [No Finding]\n",
       "34991   00009231_009.png          [No Finding]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = parser.sample(100, is_weighted=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set size:  60\n",
      "Validation set size:  20\n",
      "Test set size:  20\n"
     ]
    }
   ],
   "source": [
    "train_val, test = train_test_split(df, test_size=0.2, random_state=42)  # Split into train+val (80%) and test (20%)\n",
    "train, val = train_test_split(train_val, test_size=0.25, random_state=42)  # Split remaining data into train (60%) and val (20%)\n",
    "\n",
    "train = train.reset_index(drop=True)\n",
    "val = val.reset_index(drop=True)\n",
    "test = test.reset_index(drop=True)\n",
    "\n",
    "print(\"Training set size: \", len(train))\n",
    "print(\"Validation set size: \", len(val))\n",
    "print(\"Test set size: \", len(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Images path: d:\\MSE\\10.Deep Learning\\Group_Final\\ViT-Chest-Xray\\Project\\input\n",
      "Training batches: 2\n",
      "Validation batches: 1\n",
      "Test batches: 1\n"
     ]
    }
   ],
   "source": [
    "# PyTorch Dataset class for chest X-ray data\n",
    "class ChestXrayDataset(Dataset):\n",
    "    def __init__(self, dataframe, images_path, labels, transform=None, is_training=True):\n",
    "        self.dataframe = dataframe.reset_index(drop=True)\n",
    "        self.images_path = images_path\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "        self.is_training = is_training\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.dataframe)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        img_name = self.dataframe.iloc[idx]['Id']\n",
    "        img_path = os.path.join(self.images_path, img_name)\n",
    "        \n",
    "        # Load image\n",
    "        image = cv2.imread(img_path)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        image = Image.fromarray(image)\n",
    "        \n",
    "        # Get labels\n",
    "        label_list = self.dataframe.iloc[idx]['Label']\n",
    "        one_hot = [0 for _ in self.labels]\n",
    "        for label in label_list:\n",
    "            if label in self.labels:\n",
    "                one_hot[self.labels.index(label)] = 1\n",
    "        label = torch.tensor(one_hot, dtype=torch.float32)\n",
    "        \n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        \n",
    "        return image, label\n",
    "\n",
    "# Image directory path - since images are directly in ROOT_DIR\n",
    "IMAGES_PATH = ROOT_DIR  # Changed from os.path.join(ROOT_DIR, \"images\")\n",
    "\n",
    "# Define transforms for training (with augmentation)\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.RandomHorizontalFlip(p=0.5),\n",
    "    transforms.RandomRotation(degrees=5),\n",
    "    transforms.ColorJitter(brightness=0.1, contrast=0.1),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# Define transforms for validation/test (no augmentation)\n",
    "val_test_transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# Create PyTorch datasets\n",
    "train_dataset = ChestXrayDataset(train, IMAGES_PATH, parser.labels, transform=train_transform)\n",
    "val_dataset = ChestXrayDataset(val, IMAGES_PATH, parser.labels, transform=val_test_transform)\n",
    "test_dataset = ChestXrayDataset(test, IMAGES_PATH, parser.labels, transform=val_test_transform)\n",
    "\n",
    "# Create data loaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, num_workers=0)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False, num_workers=0)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False, num_workers=0)\n",
    "\n",
    "print(\"Images path:\", IMAGES_PATH)\n",
    "print(\"Training batches:\", len(train_loader))\n",
    "print(\"Validation batches:\", len(val_loader))\n",
    "print(\"Test batches:\", len(test_loader))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.14.0)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
