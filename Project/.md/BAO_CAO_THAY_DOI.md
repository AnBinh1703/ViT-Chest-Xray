# B√ÅO C√ÅO THAY ƒê·ªîI - D·ª∞ √ÅN CHEST X-RAY CLASSIFICATION

## L·ªãch s·ª≠ Commit

| Commit | Ng√†y | M√¥ t·∫£ |
|--------|------|-------|
| `bad7269` | - | First commit - Kh·ªüi t·∫°o d·ª± √°n |
| `b535efd` | - | Add detailed analysis for data download and ResNet model |
| `99eefe9` | - | Refactor code structure for improved readability |
| `81af87c` | - | Clear output |
| `15e684e` | 30/01/2026 | Refactor path configs for cross-platform + add config.py |
| `7aa8947` | 31/01/2026 | **Migrate from TensorFlow to PyTorch** for Python 3.14 |
| `7e667f7` | 01/02/2026 | **Migrate all notebooks to PyTorch + Fix AUC NaN + Training results** |

---

# THAY ƒê·ªîI 1: CHUY·ªÇN T·ª™ TENSORFLOW SANG PYTORCH

## Ng√†y th·ª±c hi·ªán: 31/01/2026
## Commit: `7aa8947`

## T√≥m t·∫Øt
Do Python 3.14 ch∆∞a ƒë∆∞·ª£c TensorFlow h·ªó tr·ª£ ch√≠nh th·ª©c, ch√∫ng t√¥i ƒë√£ th·ª±c hi·ªán chuy·ªÉn ƒë·ªïi to√†n b·ªô notebook `data.ipynb` t·ª´ TensorFlow/Keras sang PyTorch ƒë·ªÉ ƒë·∫£m b·∫£o t√≠nh t∆∞∆°ng th√≠ch v√† ho·∫°t ƒë·ªông ·ªïn ƒë·ªãnh.

## V·∫•n ƒë·ªÅ g·ªëc
- **L·ªói import**: `ModuleNotFoundError: No module named 'tensorflow'`
- **Nguy√™n nh√¢n**: Python 3.14 l√† phi√™n b·∫£n qu√° m·ªõi, TensorFlow ch∆∞a c√≥ wheels t∆∞∆°ng th√≠ch
- **Gi·∫£i ph√°p**: Chuy·ªÉn sang PyTorch (ƒë√£ ƒë∆∞·ª£c c√†i ƒë·∫∑t v√† t∆∞∆°ng th√≠ch v·ªõi Python 3.14)

## C√°c thay ƒë·ªïi ch√≠nh

### 1. **Thay ƒë·ªïi imports**
```python
# C≈® (TensorFlow/Keras)
import tensorflow as tf
from tensorflow.keras import layers, models
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau
from tensorflow.keras.applications.inception_resnet_v2 import InceptionResNetV2

# M·ªöI (PyTorch)
import torch
import torchvision.transforms as transforms
from torch.utils.data import Dataset, DataLoader
from torchvision import transforms
from PIL import Image
```

### 2. **S·ª≠a c·∫•u h√¨nh ƒë∆∞·ªùng d·∫´n d·ªØ li·ªáu**
```python
# C≈®
IMAGES_DIR = "images"  # T√¨m trong th∆∞ m·ª•c con images/
ROOT_DIR = os.path.join(PROJECT_ROOT, "Project", "input")

# M·ªöI  
IMAGES_DIR = "."  # T√¨m tr·ª±c ti·∫øp trong th∆∞ m·ª•c input/
ROOT_DIR = os.path.join(PROJECT_ROOT, "Project", "input")
```

**L√Ω do**: H√¨nh ·∫£nh ƒë∆∞·ª£c l∆∞u tr·ª±c ti·∫øp trong th∆∞ m·ª•c `input/` ch·ª© kh√¥ng ph·∫£i `input/images/`

### 3. **C·∫£i ti·∫øn l·ªõp DatasetParser**
```python
# Th√™m tham s·ªë images_dir v√†o _labels_by_task()
def _labels_by_task(self, root_dir=None, labels_csv=None, images_dir="."):
    # Logic x·ª≠ l√Ω linh ho·∫°t cho c·∫£ th∆∞ m·ª•c con v√† th∆∞ m·ª•c g·ªëc
    if images_dir == ".":
        image_paths = glob.glob(os.path.join(root_dir, '*.png'))
    else:
        image_paths = glob.glob(os.path.join(root_dir, images_dir, '*.png'))
```

**S·ª≠a l·ªói**: Trong method `visualize_random_images()` - thay `idxs = random(idxs, num_images)` th√†nh `idxs = random.sample(idxs, num_images)`

### 4. **T·∫°o l·ªõp Dataset cho PyTorch**
```python
class ChestXrayDataset(Dataset):
    def __init__(self, dataframe, images_path, labels, transform=None, is_training=True):
        self.dataframe = dataframe.reset_index(drop=True)
        self.images_path = images_path
        self.labels = labels
        self.transform = transform
        self.is_training = is_training
        
    def __len__(self):
        return len(self.dataframe)
    
    def __getitem__(self, idx):
        # Load image using OpenCV and PIL
        # Convert labels to one-hot tensor
        # Apply transforms
        return image, label
```

### 5. **Thay th·∫ø ImageDataGenerator b·∫±ng PyTorch transforms**
```python
# C≈® (Keras)
train_datagen = ImageDataGenerator(
    rescale=1./255,
    horizontal_flip=True,
    rotation_range=5,
    # ... other augmentations
)

# M·ªöI (PyTorch)
train_transform = transforms.Compose([
    transforms.Resize((224, 224)),
    transforms.RandomHorizontalFlip(p=0.5),
    transforms.RandomRotation(degrees=5),
    transforms.ColorJitter(brightness=0.1, contrast=0.1),
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
])
```

### 6. **Thay th·∫ø data generators b·∫±ng DataLoaders**
```python
# C≈® (Keras)
train_generator = train_datagen.flow_from_dataframe(...)
validation_generator = val_datagen.flow_from_dataframe(...)

# M·ªöI (PyTorch)
train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, num_workers=0)
val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False, num_workers=0)
```

## K·∫øt qu·∫£ sau thay ƒë·ªïi

### ‚úÖ **Th√†nh c√¥ng**
- **T·ªïng s·ªë h√¨nh ·∫£nh ph√°t hi·ªán**: 112,120 images
- **K√≠ch th∆∞·ªõc dataset**: 
  - Training: 60 samples (2 batches)
  - Validation: 20 samples (1 batch) 
  - Test: 20 samples (1 batch)
- **T·∫•t c·∫£ imports ho·∫°t ƒë·ªông**: Kh√¥ng c√≤n l·ªói ModuleNotFoundError
- **Data loading th√†nh c√¥ng**: CSV v√† images ƒë∆∞·ª£c load ƒë√∫ng c√°ch
- **PyTorch datasets v√† dataloaders**: T·∫°o th√†nh c√¥ng v√† s·∫µn s√†ng training

### üìä **Th·ªëng k√™ d·ªØ li·ªáu**
```
Data root: d:\MSE\10.Deep Learning\Group_Final\ViT-Chest-Xray\Project\input
Total Trainable Data: 112120
Training set size: 60
Validation set size: 20
Test set size: 20
Images path: d:\MSE\10.Deep Learning\Group_Final\ViT-Chest-Xray\Project\input
Training batches: 2
Validation batches: 1
Test batches: 1
```

## L·ª£i √≠ch c·ªßa vi·ªác chuy·ªÉn sang PyTorch

1. **T∆∞∆°ng th√≠ch**: Ho·∫°t ƒë·ªông ho√†n h·∫£o v·ªõi Python 3.14
2. **Hi·ªáu su·∫•t**: PyTorch c√≥ hi·ªáu su·∫•t t·ªët cho Vision Transformers
3. **Linh ho·∫°t**: D·ªÖ d√†ng custom dataset v√† transforms
4. **C·ªông ƒë·ªìng**: Nhi·ªÅu pre-trained ViT models c√≥ s·∫µn tr√™n PyTorch
5. **Debugging**: PyTorch c√≥ dynamic computation graph, d·ªÖ debug h∆°n

## Nh·ªØng file b·ªã ·∫£nh h∆∞·ªüng

- `data.ipynb`: Thay ƒë·ªïi to√†n b·ªô logic data loading
- Kh√¥ng c√≥ file n√†o kh√°c b·ªã ·∫£nh h∆∞·ªüng

## B∆∞·ªõc ti·∫øp theo

Notebook hi·ªán t·∫°i ƒë√£ s·∫µn s√†ng ƒë·ªÉ:
1. X√¢y d·ª±ng Vision Transformer models v·ªõi PyTorch
2. Training v·ªõi chest X-ray dataset  
3. S·ª≠ d·ª•ng pre-trained ViT models t·ª´ `timm` library
4. Implement c√°c ki·∫øn tr√∫c deep learning kh√°c v·ªõi PyTorch

## Ghi ch√∫ k·ªπ thu·∫≠t

- **Environment**: Python 3.14.0 v·ªõi PyTorch 2.10.0
- **Dataset**: NIH Chest X-ray Dataset v·ªõi 15 nh√£n b·ªánh
- **Image format**: PNG files, ƒë∆∞·ª£c resize v·ªÅ 224x224 cho training
- **Label encoding**: One-hot encoding cho multi-label classification
- **Data augmentation**: Horizontal flip, rotation, color jitter
- **Batch size**: 32 (c√≥ th·ªÉ ƒëi·ªÅu ch·ªânh theo GPU memory)

## Files thay ƒë·ªïi trong commit `7aa8947`

| File | Th√™m | X√≥a | M√¥ t·∫£ |
|------|------|-----|-------|
| `Project/data.ipynb` | +259 | -138 | Chuy·ªÉn t·ª´ Keras sang PyTorch DataLoader |
| `Project/cnn.ipynb` | +225 | - | Chuy·ªÉn model t·ª´ Keras sang PyTorch |
| `Project/BAO_CAO_THAY_DOI.md` | +167 | - | T√†i li·ªáu ghi ch√©p thay ƒë·ªïi |
| `Project/comprehensive_analysis.py` | +839 | - | Script ph√¢n t√≠ch project |

---

# THAY ƒê·ªîI 2: FIX AUC NaN TRONG CNN TRAINING

## Ng√†y th·ª±c hi·ªán: 01/02/2026
## Commit: *(ch∆∞a commit)*

### V·∫•n ƒë·ªÅ
Khi ch·∫°y training v·ªõi `cnn.ipynb`, gi√° tr·ªã AUC hi·ªÉn th·ªã l√† `nan` thay v√¨ gi√° tr·ªã s·ªë h·ª£p l·ªá.

### Nguy√™n nh√¢n
- `sklearn.metrics.roc_auc_score` v·ªõi `average='macro'` y√™u c·∫ßu m·ªói class ph·∫£i c√≥ **√≠t nh·∫•t 1 m·∫´u positive (1)** v√† **√≠t nh·∫•t 1 m·∫´u negative (0)**
- V·ªõi d·ªØ li·ªáu nh·ªè ho·∫∑c m·∫•t c√¢n b·∫±ng (multi-label classification v·ªõi 15 classes), m·ªôt s·ªë class c√≥ th·ªÉ ch·ªâ c√≥ to√†n 0 ho·∫∑c to√†n 1 trong m·ªôt epoch
- ƒêi·ªÅu n√†y kh√°c v·ªõi Keras `keras.metrics.AUC()` - t·ª± ƒë·ªông x·ª≠ l√Ω c√°c edge cases

### So s√°nh c√°ch t√≠nh AUC

| Keras (Original) | PyTorch (Current) |
|------------------|-------------------|
| `keras.metrics.AUC()` t√≠ch h·ª£p | `roc_auc_score()` t·ª´ sklearn |
| T·ª± ƒë·ªông x·ª≠ l√Ω edge cases | C·∫ßn x·ª≠ l√Ω th·ªß c√¥ng |
| Tr·∫£ v·ªÅ 0 n·∫øu kh√¥ng ƒë·ªß data | Tr·∫£ v·ªÅ NaN/Error |

### Gi·∫£i ph√°p √°p d·ª•ng

```python
# C≈® - G√¢y l·ªói NaN
try:
    epoch_auc = roc_auc_score(all_targets, all_outputs, average='macro')
except ValueError:
    epoch_auc = 0.0

# M·ªöI - Ch·ªâ t√≠nh AUC cho c√°c class h·ª£p l·ªá
try:
    # T√¨m c√°c class c√≥ c·∫£ positive v√† negative samples
    valid_classes = []
    for i in range(all_targets.shape[1]):
        if len(np.unique(all_targets[:, i])) > 1:
            valid_classes.append(i)
    
    if len(valid_classes) > 0:
        epoch_auc = roc_auc_score(
            all_targets[:, valid_classes], 
            all_outputs[:, valid_classes], 
            average='macro'
        )
    else:
        epoch_auc = 0.0
except ValueError:
    epoch_auc = 0.0
```

### Logic x·ª≠ l√Ω
1. Duy·ªát qua t·ª´ng class (15 classes)
2. Ki·ªÉm tra xem class ƒë√≥ c√≥ c·∫£ gi√° tr·ªã 0 v√† 1 kh√¥ng (`np.unique()`)
3. Ch·ªâ ƒë∆∞a c√°c class h·ª£p l·ªá v√†o t√≠nh AUC
4. N·∫øu kh√¥ng c√≥ class n√†o h·ª£p l·ªá, tr·∫£ v·ªÅ AUC = 0.0

### File b·ªã ·∫£nh h∆∞·ªüng
- `cnn.ipynb`: C·∫≠p nh·∫≠t h√†m `train_model()` - ph·∫ßn t√≠nh AUC cho c·∫£ training v√† validation

### K·∫øt qu·∫£
- ‚úÖ AUC kh√¥ng c√≤n hi·ªÉn th·ªã NaN
- ‚úÖ T√≠nh to√°n AUC ch√≠nh x√°c cho c√°c class c√≥ ƒë·ªß d·ªØ li·ªáu
- ‚úÖ T∆∞∆°ng th√≠ch v·ªõi d·ªØ li·ªáu m·∫•t c√¢n b·∫±ng

---

# THAY ƒê·ªîI 3: CHUY·ªÇN RESNET.IPYNB SANG PYTORCH

## Ng√†y th·ª±c hi·ªán: 01/02/2026
## Commit: *(ch∆∞a commit)*

### V·∫•n ƒë·ªÅ
- `resnet.ipynb` v·∫´n s·ª≠ d·ª•ng TensorFlow/Keras (`train_generator`, `validation_generator`)
- Nh∆∞ng `data.ipynb` ƒë√£ ƒë∆∞·ª£c chuy·ªÉn sang PyTorch (`train_loader`, `val_loader`)
- G√¢y ra l·ªói: `NameError: name 'train_generator' is not defined`

### Gi·∫£i ph√°p
Chuy·ªÉn to√†n b·ªô `resnet.ipynb` sang PyTorch ƒë·ªÉ ƒë·ªìng nh·∫•t v·ªõi project.

### C√°c thay ƒë·ªïi chi ti·∫øt

#### 1. **Imports** (Cell 2)
```python
# C≈® (TensorFlow/Keras)
import tensorflow as tf
from tensorflow.keras import layers, models
from tensorflow.keras.layers import Input, Conv2D, BatchNormalization, ...
from tensorflow.keras.models import Model

# M·ªöI (PyTorch)
import torch
import torch.nn as nn
import torch.optim as optim
from sklearn.metrics import roc_auc_score
from tqdm.notebook import tqdm
```

#### 2. **Device Configuration** (Cell 4)
```python
# C≈®
gpus = tf.config.list_physical_devices('GPU')
if torch.cuda.is_available():
    device = torch.device('cuda')
else:
    if gpus:
        device = '/GPU:0'
    else:
        device = '/CPU:0'

# M·ªöI  
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
print(f"Using device: {device}")
```

#### 3. **Model Architecture** (Cell 6)
```python
# C≈® (Keras Functional API)
def block(x, filters, strides=1):
    x = Conv2D(filters, 3, ...)(x)
    x = BatchNormalization()(x)
    ...

def create_resnet():
    inputs = Input(shape=input_shape)
    ...
    model = Model(inputs, outputs)
    return model

# M·ªöI (PyTorch nn.Module)
class BasicBlock(nn.Module):
    def __init__(self, in_channels, out_channels, stride=1, downsample=None):
        super(BasicBlock, self).__init__()
        self.conv1 = nn.Conv2d(...)
        self.bn1 = nn.BatchNorm2d(...)
        ...
    
    def forward(self, x):
        ...
        return out

class ResNet(nn.Module):
    def __init__(self, block, layers, num_classes=15):
        ...
    
    def forward(self, x):
        ...
        return x

def create_resnet34(num_classes=15):
    return ResNet(BasicBlock, [3, 4, 6, 3], num_classes=num_classes)
```

#### 4. **Training Function** (Cell 7)
```python
# C≈® (Keras)
def run_experiment(model):
    optimizer = keras.optimizers.AdamW(...)
    model.compile(optimizer=optimizer, loss='binary_crossentropy', ...)
    history = model.fit(train_generator, validation_data=validation_generator, ...)
    return history

# M·ªöI (PyTorch) - V·ªõi AUC fix
def train_model(model, train_loader, val_loader, criterion, optimizer, num_epochs=10):
    # Training loop v·ªõi tqdm progress bar
    # AUC calculation v·ªõi valid_classes check (fix NaN)
    # Model checkpoint saving
    return history
```

#### 5. **Training Execution** (Cell 8)
```python
# C≈®
resnet = create_resnet()
history_resnet = run_experiment(resnet)

# M·ªöI
model = create_resnet34(num_classes=num_classes).to(device)
criterion = nn.BCEWithLogitsLoss()
optimizer = optim.AdamW(model.parameters(), lr=learning_rate, weight_decay=weight_decay)
history = train_model(model, train_loader, val_loader, criterion, optimizer, num_epochs=num_epochs)
```

#### 6. **Plot Function** (Cell 9)
```python
# C≈® (Keras history object)
plt.plot(history.history['loss'], ...)
plt.plot(history.history['val_loss'], ...)

# M·ªöI (Python dictionary)
plt.plot(history['train_loss'], ...)
plt.plot(history['val_loss'], ...)
plt.plot(history['train_auc'], ...)
plt.plot(history['val_auc'], ...)
```

### So s√°nh ki·∫øn tr√∫c ResNet

| Aspect | Keras (C≈©) | PyTorch (M·ªõi) |
|--------|------------|---------------|
| Model type | Functional API | nn.Module class |
| Block definition | Function | BasicBlock class |
| Residual connection | `x += identity` | `out += identity` |
| Pooling | GlobalAveragePooling2D | AdaptiveAvgPool2d |
| Classifier | Dense layer | Linear layer |
| Weight init | Default | Kaiming normal |

### File b·ªã ·∫£nh h∆∞·ªüng
- `resnet.ipynb`: Chuy·ªÉn to√†n b·ªô t·ª´ TensorFlow/Keras sang PyTorch

### K·∫øt qu·∫£
- ‚úÖ T∆∞∆°ng th√≠ch v·ªõi `data.ipynb` (s·ª≠ d·ª•ng `train_loader`, `val_loader`)
- ‚úÖ S·ª≠ d·ª•ng GPU v·ªõi PyTorch CUDA
- ‚úÖ AUC fix ƒë√£ ƒë∆∞·ª£c √°p d·ª•ng (kh√¥ng c√≤n NaN)
- ‚úÖ ResNet-34 architecture v·ªõi proper weight initialization

---

# THAY ƒê·ªîI 4: CHUY·ªÇN ViT-v1.ipynb SANG PYTORCH

## Ng√†y th·ª±c hi·ªán: 01/02/2026
## Commit: *(ch∆∞a commit)*

### V·∫•n ƒë·ªÅ
- `ViT-v1.ipynb` s·ª≠ d·ª•ng TensorFlow/Keras
- C·∫ßn chuy·ªÉn sang PyTorch ƒë·ªÉ t∆∞∆°ng th√≠ch v·ªõi `data.ipynb` v√† m√¥i tr∆∞·ªùng Python 3.13

### C√°c thay ƒë·ªïi chi ti·∫øt

#### 1. **Imports**
```python
# C≈® (TensorFlow/Keras)
import tensorflow as tf
from tensorflow.keras import layers, models
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint

# M·ªöI (PyTorch)
import torch
import torch.nn as nn
import torch.nn.functional as F
import torch.optim as optim
from sklearn.metrics import roc_auc_score
from tqdm.notebook import tqdm
```

#### 2. **MLP Block**
```python
# C≈® (Keras)
def mlp(x, hidden_units, dropout_rate):
    for units in hidden_units:
        x = Dense(units, activation=tf.nn.gelu)(x)
        x = Dropout(dropout_rate)(x)
    return x

# M·ªöI (PyTorch)
class MLP(nn.Module):
    def __init__(self, in_features, hidden_features, out_features, dropout=0.1):
        super().__init__()
        self.fc1 = nn.Linear(in_features, hidden_features)
        self.fc2 = nn.Linear(hidden_features, out_features)
        self.dropout = nn.Dropout(dropout)
        
    def forward(self, x):
        x = F.gelu(self.fc1(x))
        x = self.dropout(x)
        x = self.fc2(x)
        x = self.dropout(x)
        return x
```

#### 3. **Patch Embedding**
```python
# C≈® (Keras custom layer)
class Patches(layers.Layer):
    def call(self, images):
        patches = tf.image.extract_patches(...)
        return patches

# M·ªöI (PyTorch nn.Module)
class PatchEmbedding(nn.Module):
    def __init__(self, img_size=224, patch_size=32, in_channels=3, embed_dim=64):
        self.proj = nn.Conv2d(in_channels, embed_dim, kernel_size=patch_size, stride=patch_size)
    
    def forward(self, x):
        x = self.proj(x)
        x = x.flatten(2).transpose(1, 2)
        return x
```

#### 4. **Transformer Encoder Block**
```python
# C≈® (Keras layers)
x1 = LayerNormalization()(encoded_patches)
attention_output = MultiHeadAttention(num_heads, key_dim)(x1, x1)
x2 = Add()([attention_output, encoded_patches])

# M·ªöI (PyTorch nn.Module)
class TransformerEncoderBlock(nn.Module):
    def __init__(self, embed_dim, num_heads, mlp_ratio=4, dropout=0.1):
        self.ln1 = nn.LayerNorm(embed_dim)
        self.attn = nn.MultiheadAttention(embed_dim, num_heads, dropout=dropout, batch_first=True)
        self.ln2 = nn.LayerNorm(embed_dim)
        self.mlp = MLP(embed_dim, int(embed_dim * mlp_ratio), embed_dim, dropout)
```

#### 5. **Vision Transformer Model**
```python
# M·ªöI - VisionTransformer class v·ªõi:
# - PatchEmbedding layer
# - Learnable positional embedding
# - Transformer encoder blocks
# - Classification head v·ªõi MLP
# - Proper weight initialization (trunc_normal_)
```

#### 6. **Training Function**
- S·ª≠ d·ª•ng PyTorch training loop v·ªõi tqdm progress bar
- AUC calculation v·ªõi valid_classes check (fix NaN)
- Model checkpoint saving

### File b·ªã ·∫£nh h∆∞·ªüng
- `ViT-v1.ipynb`: Chuy·ªÉn to√†n b·ªô t·ª´ TensorFlow/Keras sang PyTorch

### K·∫øt qu·∫£
- ‚úÖ Vision Transformer from scratch v·ªõi PyTorch
- ‚úÖ T∆∞∆°ng th√≠ch v·ªõi `data.ipynb` DataLoaders
- ‚úÖ AUC fix ƒë√£ ƒë∆∞·ª£c √°p d·ª•ng
- ‚úÖ ROC curve plotting

---

# THAY ƒê·ªîI 5: CHUY·ªÇN ViT-v2.ipynb SANG PYTORCH

## Ng√†y th·ª±c hi·ªán: 01/02/2026
## Commit: *(ch∆∞a commit)*

### V·∫•n ƒë·ªÅ
- `ViT-v2.ipynb` l√† phi√™n b·∫£n c·∫£i ti·∫øn c·ªßa ViT-v1 v·ªõi regularization
- C·∫ßn chuy·ªÉn sang PyTorch t∆∞∆°ng t·ª± ViT-v1

### C√°c thay ƒë·ªïi chi ti·∫øt
T∆∞∆°ng t·ª± ViT-v1, v·ªõi c√°c b·ªï sung:

#### 1. **Early Stopping**
```python
# C≈® (Keras callback)
early_stopping = EarlyStopping(monitor="val_accuracy", patience=3, restore_best_weights=False)

# M·ªöI (PyTorch manual implementation)
patience_counter = 0
if epoch_val_loss < best_val_loss:
    patience_counter = 0
    torch.save(model.state_dict(), save_path)
else:
    patience_counter += 1
    if patience_counter >= patience:
        print('Early stopping triggered')
        break
```

#### 2. **Learning Rate Scheduler**
```python
# C≈® (Keras callback)
lr_scheduler = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=5)

# M·ªöI (PyTorch)
from torch.optim.lr_scheduler import ReduceLROnPlateau
scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=5, min_lr=1e-6)
scheduler.step(epoch_val_loss)
```

#### 3. **Multiple Optimizer Options**
```python
def get_optimizer(model, optimizer_name='sgd'):
    optimizers = {
        "adam": optim.Adam(model.parameters(), lr=learning_rate),
        "adamw": optim.AdamW(model.parameters(), lr=learning_rate, weight_decay=weight_decay),
        "sgd": optim.SGD(model.parameters(), lr=0.01, momentum=0.9, nesterov=True),
        ...
    }
    return optimizers.get(optimizer_name)
```

### File b·ªã ·∫£nh h∆∞·ªüng
- `ViT-v2.ipynb`: Chuy·ªÉn to√†n b·ªô t·ª´ TensorFlow/Keras sang PyTorch

### K·∫øt qu·∫£
- ‚úÖ ViT-v2 v·ªõi early stopping v√† LR scheduler
- ‚úÖ Multiple optimizer options
- ‚úÖ Tracking learning rate trong history
- ‚úÖ AUC fix ƒë√£ ƒë∆∞·ª£c √°p d·ª•ng

---

# THAY ƒê·ªîI 6: C·∫¨P NH·∫¨T ViT-ResNet.ipynb

## Ng√†y th·ª±c hi·ªán: 01/02/2026
## Commit: *(ch∆∞a commit)*

### V·∫•n ƒë·ªÅ
- `ViT-ResNet.ipynb` ƒë√£ d√πng PyTorch nh∆∞ng c√≥ data loading ri√™ng
- C·∫ßn c·∫≠p nh·∫≠t ƒë·ªÉ s·ª≠ d·ª•ng `data.ipynb` gi·ªëng c√°c notebook kh√°c

### C√°c thay ƒë·ªïi chi ti·∫øt

#### 1. **X√≥a data loading code**
- X√≥a `ChestXRayDataset` class (ƒë√£ c√≥ trong data.ipynb)
- X√≥a path configuration
- X√≥a data split v√† DataLoader creation

#### 2. **S·ª≠ d·ª•ng data.ipynb**
```python
# M·ªöI
%run data.ipynb
# S·ª≠ d·ª•ng train_loader, val_loader, test_loader t·ª´ data.ipynb
```

#### 3. **Th√™m AUC fix**
- √Åp d·ª•ng valid_classes check trong training function
- T∆∞∆°ng t·ª± c√°c notebook kh√°c

### File b·ªã ·∫£nh h∆∞·ªüng
- `ViT-ResNet.ipynb`: C·∫≠p nh·∫≠t data loading v√† AUC calculation

### K·∫øt qu·∫£
- ‚úÖ S·ª≠ d·ª•ng chung data.ipynb v·ªõi c√°c notebook kh√°c
- ‚úÖ Pre-trained ViT (vit_base_patch16_224) t·ª´ timm
- ‚úÖ AUC fix ƒë√£ ƒë∆∞·ª£c √°p d·ª•ng

---

## T·ªîNG K·∫æT THAY ƒê·ªîI

| Notebook | Tr·∫°ng th√°i ban ƒë·∫ßu | Thay ƒë·ªïi | Tr·∫°ng th√°i cu·ªëi |
|----------|-------------------|----------|-----------------|
| `data.ipynb` | TensorFlow | ‚Üí PyTorch | ‚úÖ PyTorch DataLoaders |
| `cnn.ipynb` | TensorFlow | ‚Üí PyTorch + AUC fix | ‚úÖ PyTorch CNN |
| `resnet.ipynb` | TensorFlow | ‚Üí PyTorch + AUC fix | ‚úÖ PyTorch ResNet-34 |
| `ViT-v1.ipynb` | TensorFlow | ‚Üí PyTorch + AUC fix | ‚úÖ PyTorch ViT from scratch |
| `ViT-v2.ipynb` | TensorFlow | ‚Üí PyTorch + AUC fix | ‚úÖ PyTorch ViT v2 (w/ early stopping) |
| `ViT-ResNet.ipynb` | PyTorch (ƒë·ªôc l·∫≠p) | ‚Üí D√πng data.ipynb + AUC fix | ‚úÖ Pre-trained ViT (timm) |

## C√°ch ch·∫°y notebooks

1. **Chuy·ªÉn kernel sang Python 3.13 (.venv313)**
2. **Ch·∫°y theo th·ª© t·ª±**:
   - `data.ipynb` (load data)
   - Sau ƒë√≥ ch·∫°y b·∫•t k·ª≥ model notebook n√†o

## L∆∞u √Ω quan tr·ªçng
- **Kh√¥ng d√πng Python 3.14** v·ªõi TensorFlow (kh√¥ng t∆∞∆°ng th√≠ch)
- **D√πng .venv313** (Python 3.13.7) v·ªõi PyTorch CUDA
- **GPU**: NVIDIA GeForce RTX 3060 Laptop GPU

---

# THAY ƒê·ªîI 7: FIX ReduceLROnPlateau VERBOSE ERROR

## Ng√†y th·ª±c hi·ªán: 01/02/2026
## Commit: *(ch∆∞a commit)*

### V·∫•n ƒë·ªÅ
Khi ch·∫°y ViT-v2.ipynb, g·∫∑p l·ªói:
```
TypeError: ReduceLROnPlateau.__init__() got an unexpected keyword argument 'verbose'
```

### Nguy√™n nh√¢n
- PyTorch 2.10+ ƒë√£ lo·∫°i b·ªè tham s·ªë `verbose` trong `ReduceLROnPlateau`
- Code c≈© s·ª≠ d·ª•ng `verbose=True` kh√¥ng c√≤n t∆∞∆°ng th√≠ch

### Gi·∫£i ph√°p
```python
# C≈® (g√¢y l·ªói)
scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=5, min_lr=1e-6, verbose=True)

# M·ªöI (ƒë√£ fix)
scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=5, min_lr=1e-6)
```

### File b·ªã ·∫£nh h∆∞·ªüng
- `ViT-v2.ipynb`: Cell t·∫°o scheduler

### K·∫øt qu·∫£
- ‚úÖ ViT-v2.ipynb ch·∫°y th√†nh c√¥ng
- ‚úÖ Training ho√†n t·∫•t v·ªõi early stopping

---

## K·∫æT QU·∫¢ TRAINING (01/02/2026)

| Model | Parameters | Test Accuracy | Test AUC | Best |
|-------|------------|---------------|----------|------|
| **ViT-v1** | 9M | **91.33%** üèÜ | 0.5854 | Accuracy |
| **ViT-v2** | 9M | 89.67% | 0.6303 | - |
| **Pre-trained ViT** | 86M | 87.00% | **0.6694** üèÜ | AUC |

### Ghi ch√∫
- Dataset nh·ªè (60 training samples) n√™n k·∫øt qu·∫£ ch∆∞a ƒë√°ng tin c·∫≠y
- C·∫ßn tƒÉng dataset ƒë·ªÉ ƒë√°nh gi√° th·ª±c t·∫ø

---
**Th·ªùi gian ho√†n th√†nh**: ~30 ph√∫t (data migration) + 10 ph√∫t (AUC fix) + 15 ph√∫t (ResNet) + 20 ph√∫t (ViT-v1) + 15 ph√∫t (ViT-v2) + 10 ph√∫t (ViT-ResNet) + 5 ph√∫t (fix verbose)  
**Status**: ‚úÖ HO√ÄN TH√ÄNH