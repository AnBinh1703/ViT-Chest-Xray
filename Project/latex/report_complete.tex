% !TEX program = xelatex
% ============================================================
%  BÁO CÁO NGHIÊN CỨU CHUYÊN SÂU (1 FILE LaTeX)
%  Chủ đề: So sánh CNN, ResNet và Vision Transformer cho phân loại đa nhãn bệnh X-quang ngực
%  Biên dịch khuyến nghị: XeLaTeX -> XeLaTeX (không cần Biber/BibTeX)
%  PHIÊN BẢN ĐẦY ĐỦ - BAO GỒM CÔNG VIỆC THỰC HIỆN TRÊN PROJECT
% ============================================================

\documentclass[12pt,a4paper,oneside]{report}

% =========================
% Unicode + Fonts (XeLaTeX)
% =========================
\usepackage{fontspec}
\setmainfont{TeX Gyre Termes}      % Times-like (thường có sẵn)
\setsansfont{TeX Gyre Heros}
\setmonofont{Inconsolata}

% =========================
% Page / Typography
% =========================
\usepackage[a4paper,margin=2.5cm]{geometry}
\usepackage{setspace}
\onehalfspacing
\usepackage{parskip}
\usepackage{indentfirst}

% =========================
% Math / Tables / Figures
% =========================
\usepackage{amsmath,amssymb,mathtools}
\usepackage{booktabs}
\usepackage{longtable}
\usepackage{array}
\usepackage{multirow}
\usepackage{graphicx}
\usepackage{float}
\usepackage{subcaption}
\usepackage{caption}
\usepackage{siunitx}

% =========================
% Links
% =========================
\usepackage{hyperref}
\hypersetup{
  colorlinks=true,
  linkcolor=blue,
  citecolor=blue,
  urlcolor=blue
}

% =========================
% Lists / Code
% =========================
\usepackage{enumitem}
\setlist[itemize]{leftmargin=1.2cm}
\setlist[enumerate]{leftmargin=1.2cm}

\usepackage{xcolor}
\usepackage{listings}
\lstset{
  basicstyle=\ttfamily\small,
  breaklines=true,
  columns=fullflexible,
  frame=single,
  rulecolor=\color{black!30},
  backgroundcolor=\color{black!2},
  tabsize=2,
  showstringspaces=false,
  keywordstyle=\color{blue},
  commentstyle=\color{green!60!black},
  stringstyle=\color{red!70!black}
}

% =========================
% Macros
% =========================
\newcommand{\PaperTitle}{A Comparative Study of CNN, ResNet, and Vision Transformers for Multi-Classification of Chest Diseases}
\newcommand{\Dataset}{NIH ChestX-ray14}
\newcommand{\Task}{phân loại đa nhãn (multi-label classification)}
\newcommand{\CNN}{\textsc{CNN}}
\newcommand{\ResNet}{\textsc{ResNet}}
\newcommand{\ViT}{\textsc{ViT}}
\newcommand{\AUC}{\textsc{AUC}}
\newcommand{\ROC}{\textsc{ROC}}
\newcommand{\BCE}{\textsc{BCE}}
\newcommand{\K}{K} % số nhãn

% =========================
% Document
% =========================
\begin{document}

% ============================================================
% TITLE PAGE
% ============================================================
\begin{titlepage}
\centering
\vspace*{1.2cm}

{\Large \textbf{BÁO CÁO NGHIÊN CỨU CHUYÊN SÂU}}\\[0.4cm]
{\LARGE \textbf{ĐÁNH GIÁ HIỆU NĂNG CÁC MÔ HÌNH HỌC SÂU TRONG CHẨN ĐOÁN BỆNH LÝ LỒNG NGỰC}}\\[0.2cm]
{\large \textbf{Phân tích so sánh \CNN, \ResNet\ và \ViT\ trên tập dữ liệu \Dataset}}\\[0.6cm]

\begin{tabular}{@{}rl@{}}
\textbf{Paper phân tích:} & \PaperTitle \\
\textbf{Nguồn paper:} & arXiv:2406.00237 \\
\textbf{Nguồn mã gốc:} & GitHub: Aviral-03/ViT-Chest-Xray \\
\textbf{Nguồn dữ liệu:} & NIH Chest X-ray (Kaggle mirror) \\
\textbf{Phiên bản cải tiến:} & PyTorch Migration (02/2026) \\
\end{tabular}

\vfill
{\large \today}
\end{titlepage}

\pagenumbering{roman}

% ============================================================
% ABSTRACT
% ============================================================
\chapter*{Tóm tắt (Abstract)}
\addcontentsline{toc}{chapter}{Tóm tắt (Abstract)}
Báo cáo này phân tích chuyên sâu nội dung học thuật, phương pháp luận và các hàm ý nghiên cứu của bài báo \cite{jain2024}.
Đối tượng so sánh gồm ba họ kiến trúc quan trọng trong học sâu thị giác: \CNN\ (baseline tuỳ chỉnh), \ResNet\ (đại diện mạng CNN sâu với residual learning) và \ViT\ (mô hình dựa trên self-attention).
Bài toán là \Task\ bệnh lý trên ảnh X-quang lồng ngực với dữ liệu \Dataset.

Khác với tóm lược ``điểm số'', báo cáo tập trung: (i) định nghĩa đúng bài toán đa nhãn, loss và metric; (ii) phân tích bản chất toán học/kiến trúc (inductive bias, receptive field, attention, độ phụ thuộc dữ liệu); (iii) bóc tách thiết kế thí nghiệm và rủi ro sai lệch (imbalance, nhãn yếu, leakage do split); (iv) diễn giải kết quả định lượng và định tính (attention maps); (v) phê bình các điểm chưa nhất quán trong paper và đề xuất hướng cải tiến để tái lập/mở rộng theo chuẩn nghiên cứu.

\textbf{Đóng góp bổ sung:} Báo cáo còn trình bày chi tiết quá trình tái lập và cải tiến codebase gốc, bao gồm: chuyển đổi từ TensorFlow sang PyTorch để tương thích Python 3.13+, chuẩn hoá pipeline dữ liệu, sửa lỗi tính AUC, và kết quả thực nghiệm.

\chapter*{Từ khóa}
\addcontentsline{toc}{chapter}{Từ khóa}
Chest X-ray; Multi-label classification; CNN; ResNet; Vision Transformer; ROC-AUC; Class imbalance; Interpretability; Reproducibility; PyTorch Migration.

\tableofcontents
\listoftables
\listoffigures

\clearpage
\pagenumbering{arabic}

% ============================================================
% CHAPTER 0: EXECUTIVE OVERVIEW
% ============================================================
\chapter{Tổng quan điều hành và phạm vi nghiên cứu}
\section{Bối cảnh: từ rule-based CAD đến học sâu}
AI trong chẩn đoán hình ảnh y tế đã chuyển dịch từ các hệ thống hỗ trợ dựa trên quy tắc (\textit{rule-based CAD}) sang các mô hình học sâu.
Trong giai đoạn đầu, \CNN\ thống trị nhờ khả năng trích xuất đặc trưng cục bộ và bất biến dịch chuyển (translation invariance), phù hợp trực giác thị giác.
Tuy nhiên, sự xuất hiện của kiến trúc Transformer trong thị giác (\ViT) với cơ chế \textit{global self-attention} đã tạo ra một ``đổi mô hình'' (paradigm shift) về cách biểu diễn ảnh: ảnh được xem như chuỗi token, và quan hệ không gian được học thông qua attention thay vì tích chập \cite{dosovitskiy2021}.

\section{Mục tiêu và câu hỏi nghiên cứu của bài báo}
Bài báo \cite{jain2024} đặt mục tiêu so sánh hiệu năng tương đối của \CNN, \ResNet, \ViT\ trên \Dataset\ cho bài toán phân loại nhiều bệnh.
Các câu hỏi cốt lõi (diễn dịch từ phần giới thiệu/mục tiêu và thiết kế thực nghiệm):
\begin{itemize}
  \item \textbf{Q1:} \CNN\ baseline, \ResNet\ và \ViT\ khác nhau thế nào về hiệu năng đo bằng accuracy và \ROC-\AUC?
  \item \textbf{Q2:} \ViT\ huấn luyện \textit{from scratch} có đủ dữ liệu để học đặc trưng y khoa không, hay cần pretraining quy mô lớn?
  \item \textbf{Q3:} Mô hình lai (hybrid) kết hợp CNN backbone + Transformer encoder có tận dụng được ưu điểm ``cục bộ + toàn cục'' hay không?
  \item \textbf{Q4:} Attention maps có giúp tăng tính diễn giải, qua đó tăng độ tin cậy lâm sàng của hệ thống không?
\end{itemize}

\section{Phạm vi báo cáo (scope) và nguyên tắc phân tích}
Báo cáo này:
\begin{enumerate}
  \item Trình bày lại đầy đủ các cấu phần paper: bài toán, dữ liệu, mô hình, thiết lập thí nghiệm, kết quả, interpretability, hạn chế và kết luận.
  \item Bổ sung phân tích chuyên sâu: inductive bias, data hunger, tác động imbalance, rủi ro leakage, và chuẩn hoá đánh giá multi-label.
  \item Đưa ra khuyến nghị tái lập/mở rộng dựa trên thực hành nghiên cứu hiện đại.
  \item \textbf{Trình bày chi tiết quá trình tái lập và cải tiến codebase} (Chương \ref{chap:implementation}).
\end{enumerate}

% ============================================================
% CHAPTER 1: CLINICAL + DATA ECOSYSTEM
% ============================================================
\chapter{Bối cảnh lâm sàng và hệ sinh thái dữ liệu}
\section{Vai trò của X-quang lồng ngực trong chẩn đoán}
X-quang lồng ngực là xét nghiệm hình ảnh thường quy, chi phí thấp, hỗ trợ phát hiện nhiều bất thường liên quan phổi, tim và màng phổi.
Trong thực tế lâm sàng, X-quang thường là tuyến đầu sàng lọc; do đó bài toán tự động hoá trên X-quang có giá trị ứng dụng cao.
Bài báo nhấn mạnh động lực hỗ trợ bác sĩ trước khối lượng dữ liệu lớn và biến thiên giữa người đọc \cite{jain2024}.

\section{Tập dữ liệu \Dataset: quy mô và nguồn nhãn}
Theo bài báo, \Dataset\ gồm 112{,}120 ảnh từ 30{,}805 bệnh nhân \cite{jain2024}.
Dữ liệu gắn nhãn yếu (weak labels) bằng khai phá văn bản báo cáo (text-mining), phù hợp với mô tả trong công bố bộ dữ liệu dòng ChestX-ray8/14 \cite{wang2017}.

\subsection{Tính chất đa nhãn: một bệnh nhân có thể có nhiều bệnh}
Trong chẩn đoán X-quang, một ảnh có thể đồng thời biểu hiện nhiều bệnh lý (ví dụ atelectasis + effusion).
Do đó bài toán đúng bản chất là \textbf{multi-label}, không phải multi-class đơn nhãn.
Hệ quả: lớp đầu ra dùng sigmoid độc lập theo nhãn và tối ưu bằng \BCE.

\section{Mất cân bằng lớp (class imbalance): thách thức trung tâm}
\subsection{Vì sao imbalance nguy hiểm trong multi-label?}
Trong dữ liệu lệch, gradient trong tối ưu hoá bị chi phối bởi lớp phổ biến.
Nếu mô hình tối ưu mạnh theo lớp ``No Finding'' (chiếm tỷ lệ lớn), nó có thể đạt accuracy cao nhưng bỏ qua lớp hiếm (Hernia, Pneumonia), làm giảm giá trị lâm sàng.

\subsection{Thống kê tần suất nhãn (label frequency)}
Bảng \ref{tab:class_dist} trình bày thống kê tần suất nhãn trong \Dataset.
\begin{longtable}{@{}p{5.2cm}rr@{}}
\caption{Tần suất nhãn trong \Dataset\ (đếm theo số ảnh mang nhãn).}
\label{tab:class_dist}\\
\toprule
\textbf{Nhãn} & \textbf{Số ảnh} & \textbf{Tỷ lệ (\%)}\\
\midrule
\endfirsthead
\toprule
\textbf{Nhãn} & \textbf{Số ảnh} & \textbf{Tỷ lệ (\%)}\\
\midrule
\endhead
No Finding & 60{,}361 & 53.84 \\
Infiltration & 19{,}894 & 17.74 \\
Effusion & 13{,}317 & 11.88 \\
Atelectasis & 11{,}559 & 10.31 \\
Nodule & 6{,}331 & 5.65 \\
Mass & 5{,}782 & 5.16 \\
Pneumothorax & 5{,}302 & 4.73 \\
Consolidation & 4{,}667 & 4.16 \\
Pleural Thickening & 3{,}385 & 3.02 \\
Cardiomegaly & 2{,}776 & 2.48 \\
Emphysema & 2{,}516 & 2.24 \\
Edema & 2{,}303 & 2.05 \\
Fibrosis & 1{,}686 & 1.50 \\
Pneumonia & 1{,}431 & 1.28 \\
Hernia & 227 & 0.20 \\
\bottomrule
\end{longtable}

\section{Tiền xử lý và tăng cường dữ liệu}
\subsection{Chuẩn hoá kích thước ảnh}
Bài báo chuẩn hoá ảnh về 224$\times$224 \cite{jain2024}.
Đây là lựa chọn thực dụng (phù hợp backbone thị giác phổ biến), nhưng là một đánh đổi về độ phân giải.

\subsection{Augmentation}
Paper sử dụng augmentation gồm resizing, horizontal flip và rotation \cite{jain2024}.
Trong X-quang, flip ngang có thể tạo ra tình huống giải phẫu ``đảo'', cần thận trọng.

% ============================================================
% CHAPTER 2: PROBLEM FORMULATION + METRICS
% ============================================================
\chapter{Mô hình hoá bài toán và tiêu chí đánh giá}
\section{Định nghĩa bài toán \Task}
Gọi $x$ là ảnh X-quang, và $y\in\{0,1\}^{\K}$ là vector nhãn với $\K$ bệnh (paper nhắc 14 bệnh và ``No Finding'', đôi khi mô tả là 15 classes) \cite{jain2024}.
Mô hình trả logits $z\in\mathbb{R}^{\K}$ và xác suất dự đoán:
\[
\hat{y}_k = \sigma(z_k) = \frac{1}{1+e^{-z_k}}.
\]

\section{Hàm mất mát: Binary Cross-Entropy}
\begin{equation}
\mathcal{L}_{\mathrm{BCE}}(y,\hat{y}) = -\sum_{k=1}^{\K}\left[y_k\log(\hat y_k)+(1-y_k)\log(1-\hat y_k)\right].
\end{equation}

\section{\ROC-\AUC: ý nghĩa và biến thể}
\subsection{AUC theo lớp}
\[
\mathrm{AUC}_k = \int_0^1 \mathrm{TPR}_k(\mathrm{FPR}_k)\, d(\mathrm{FPR}_k).
\]
\subsection{Macro AUC}
\[
\mathrm{AUC}_{macro} = \frac{1}{\K}\sum_{k=1}^{\K}\mathrm{AUC}_k.
\]

% ============================================================
% CHAPTER 3: MODEL ARCHITECTURES
% ============================================================
\chapter{Phân tích chuyên sâu kiến trúc mô hình}
\section{\CNN\ baseline}
Paper mô tả \CNN\ baseline dạng: Conv(32)$\rightarrow$MaxPool$\rightarrow$Conv(64)$\rightarrow$MaxPool$\rightarrow$Dense(512)$\rightarrow$Dense(sigmoid) \cite{jain2024}.

\subsection{Tích chập 2D}
\[
(\mathbf{X}*\mathbf{W})(i,j)=\sum_{u}\sum_{v}\mathbf{X}(i+u,j+v)\mathbf{W}(u,v).
\]

\section{\ResNet: residual learning}
\subsection{Residual block}
\[
\mathbf{y} = \mathcal{F}(\mathbf{x}) + \mathbf{x}.
\]

\section{\ViT: self-attention toàn cục}
\subsection{Patch embedding}
\[
N=\left(\frac{H}{P}\right)\left(\frac{W}{P}\right).
\]

\subsection{Multi-Head Self-Attention}
\[
\mathrm{Attn}(Q,K,V)=\mathrm{softmax}\left(\frac{QK^\top}{\sqrt{d}}\right)V.
\]

% ============================================================
% CHAPTER 4: EXPERIMENTAL DESIGN
% ============================================================
\chapter{Thiết kế thí nghiệm}
\section{Loss/Optimizer/Scheduler theo paper}
\begin{itemize}
  \item ViT-v1/32: AdamW + BCE
  \item ViT-v2/32: SGD + BCE + ReduceLROnPlateau
  \item Hybrid ViT-ResNet/16: Adam + BCE-with-logits + pretraining ImageNet-21k
\end{itemize}

% ============================================================
% CHAPTER 5: RESULTS
% ============================================================
\chapter{Kết quả và phân tích}
\section{Bảng kết quả theo paper}
\begin{table}[H]
\centering
\caption{Kết quả theo paper: accuracy và \AUC.}
\label{tab:paper_results}
\begin{tabular}{@{}lcccc@{}}
\toprule
\textbf{Mô hình} & \textbf{Test Acc (\%)} & \textbf{Train Acc (\%)} & \textbf{Val Acc (\%)} & \textbf{AUC}\\
\midrule
CNN & 91.00 & 92.62 & 92.68 & 0.82\\
ResNet & 93.00 & 93.38 & 93.34 & 0.86\\
ViT-v1 & 92.63 & 92.70 & 92.89 & 0.86\\
ViT-v2 & 92.83 & 92.94 & 92.95 & 0.84\\
ViT-ResNet & 93.90 & 93.02 & 94.07 & 0.85\\
\bottomrule
\end{tabular}
\end{table}

% ============================================================
% CHAPTER 6: INTERPRETABILITY
% ============================================================
\chapter{Khả năng diễn giải}
\section{Attention maps}
Paper trích attention từ lớp MHA cuối, trung bình theo head, resize và overlay lên ảnh \cite{jain2024}.

\section{Grad-CAM}
\[
L^c = \mathrm{ReLU}\left(\sum_k \alpha_k^c A^k\right).
\]

% ============================================================
% CHAPTER 7: CRITICAL REVIEW
% ============================================================
\chapter{Phê bình học thuật}
\section{Mâu thuẫn thuật ngữ}
Paper đôi khi dùng ``multi-class'' nhưng thiết kế là multi-label.

\section{Rủi ro leakage}
Paper không mô tả rõ patient-level split.

% ============================================================
% CHAPTER 8: EXTENSIONS
% ============================================================
\chapter{Hướng mở rộng}
\section{Xử lý imbalance: Focal Loss}
\[
\mathcal{L}_{focal} = -\sum_{k=1}^{\K}\left[
\alpha_k(1-\hat y_k)^\gamma y_k\log(\hat y_k) + (1-\alpha_k)\hat y_k^\gamma (1-y_k)\log(1-\hat y_k)
\right].
\]

% ============================================================
% CHAPTER 9: PROJECT PLAN
% ============================================================
\chapter{Kế hoạch triển khai nhóm}
\section{Phân công}
\subsection*{Người A — \CNN/\ResNet}
\subsection*{Người B — \ViT\ \& hybrid}
\subsection*{Người C — Dataset, metric, phê bình}

% ============================================================
% CHAPTER 10: IMPLEMENTATION (MỚI - CÔNG VIỆC THỰC HIỆN)
% ============================================================
\chapter{Triển khai thực nghiệm: Cải tiến codebase}
\label{chap:implementation}

Chương này trình bày chi tiết các thay đổi đã thực hiện trên codebase gốc từ repository \texttt{Aviral-03/ViT-Chest-Xray} \cite{aviralrepo}.

\section{Tổng quan thay đổi so với bản gốc}

\subsection{Vấn đề với codebase gốc}
\begin{enumerate}
  \item \textbf{Tương thích phiên bản Python:} TensorFlow chưa hỗ trợ Python 3.13+
  \item \textbf{Thiếu nhất quán data pipeline:} Mỗi notebook có cách load dữ liệu riêng
  \item \textbf{Đường dẫn hardcoded:} Không tương thích Windows
  \item \textbf{Lỗi tính AUC:} Sklearn trả về NaN khi thiếu mẫu
\end{enumerate}

\subsection{Giải pháp: Migration sang PyTorch}
Chuyển toàn bộ codebase sang PyTorch vì:
\begin{itemize}
  \item Tương thích tốt với Python 3.13+
  \item Hiệu suất cao cho Vision Transformers
  \item Thư viện \texttt{timm} cung cấp pre-trained ViT models
  \item Dễ debug (dynamic computation graph)
\end{itemize}

\section{Chi tiết các thay đổi kỹ thuật}

\subsection{Thay đổi 1: Chuẩn hoá cấu hình}
Tạo file \texttt{config.py} tập trung quản lý cấu hình cross-platform:
\begin{lstlisting}[language=Python]
import os

PROJECT_ROOT = get_project_root()
DATA_ROOT = os.path.join(PROJECT_ROOT, "Project", "input")
IMAGE_SIZE = 224
BATCH_SIZE = 32
NUM_CLASSES = 15
LABELS = ['Cardiomegaly', 'Emphysema', 'Effusion', ...]
\end{lstlisting}

\subsection{Thay đổi 2: Data Pipeline PyTorch}
\begin{lstlisting}[language=Python]
class ChestXrayDataset(Dataset):
    def __init__(self, dataframe, images_path, labels, transform=None):
        self.dataframe = dataframe.reset_index(drop=True)
        self.transform = transform
        
    def __getitem__(self, idx):
        img_path = os.path.join(self.images_path, img_name)
        image = Image.open(img_path).convert('RGB')
        if self.transform:
            image = self.transform(image)
        label = torch.tensor(self.dataframe.iloc[idx][self.labels].values)
        return image, label

train_transform = transforms.Compose([
    transforms.Resize((224, 224)),
    transforms.RandomHorizontalFlip(p=0.5),
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.485, 0.456, 0.406], 
                        std=[0.229, 0.224, 0.225])
])
\end{lstlisting}

\subsection{Thay đổi 3: Sửa lỗi AUC NaN}
\begin{lstlisting}[language=Python]
def calculate_auc_safe(targets, outputs):
    """Calculate AUC only for classes with both 0 and 1 samples."""
    valid_classes = []
    for i in range(targets.shape[1]):
        if len(np.unique(targets[:, i])) > 1:
            valid_classes.append(i)
    
    if len(valid_classes) > 0:
        return roc_auc_score(
            targets[:, valid_classes], 
            outputs[:, valid_classes], 
            average='macro'
        )
    return 0.0
\end{lstlisting}

\subsection{Thay đổi 4-6: Migration các Models}

\begin{table}[H]
\centering
\caption{Tổng hợp các thay đổi trên từng notebook.}
\begin{tabular}{@{}p{2.5cm}p{3cm}p{4cm}@{}}
\toprule
\textbf{Notebook} & \textbf{Trạng thái gốc} & \textbf{Trạng thái mới} \\
\midrule
\texttt{data.ipynb} & TensorFlow & PyTorch DataLoaders \\
\texttt{cnn.ipynb} & TensorFlow & PyTorch CNN + AUC fix \\
\texttt{resnet.ipynb} & TensorFlow & PyTorch ResNet-34 \\
\texttt{ViT-v1.ipynb} & TensorFlow & PyTorch ViT from scratch \\
\texttt{ViT-v2.ipynb} & TensorFlow & PyTorch ViT + early stopping \\
\texttt{ViT-ResNet.ipynb} & PyTorch (riêng) & Pre-trained ViT (timm) \\
\bottomrule
\end{tabular}
\end{table}

\subsection{Thay đổi 7: Fix ReduceLROnPlateau}
PyTorch 2.10+ loại bỏ tham số \texttt{verbose}:
\begin{lstlisting}[language=Python]
# Cu (loi)
scheduler = ReduceLROnPlateau(optimizer, verbose=True)

# Moi (da fix)
scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=5)
\end{lstlisting}

\section{Kết quả thực nghiệm}

\subsection{Môi trường thực nghiệm}
\begin{itemize}
  \item \textbf{Python}: 3.13.7
  \item \textbf{PyTorch}: 2.10.0+cu126
  \item \textbf{GPU}: NVIDIA GeForce RTX 3060 Laptop GPU
  \item \textbf{CUDA}: 12.6
\end{itemize}

\subsection{Kết quả training}
\begin{table}[H]
\centering
\caption{Kết quả thực nghiệm (dataset: 60 train / 20 val / 20 test).}
\label{tab:our_results}
\begin{tabular}{@{}lcccc@{}}
\toprule
\textbf{Mô hình} & \textbf{Params} & \textbf{Test Acc (\%)} & \textbf{Test AUC} & \textbf{Best} \\
\midrule
ViT-v1 (from scratch) & $\sim$9M & \textbf{91.33} & 0.5854 & Accuracy \\
ViT-v2 (early stopping) & $\sim$9M & 89.67 & 0.6303 & - \\
Pre-trained ViT (timm) & $\sim$86M & 87.00 & \textbf{0.6694} & AUC \\
\bottomrule
\end{tabular}
\end{table}

\textbf{Lưu ý:} Dataset thực nghiệm rất nhỏ (60 training samples), kết quả chưa đáng tin cậy. Cần tăng dataset để đánh giá chính xác.

\section{Lịch sử commit}
\begin{table}[H]
\centering
\caption{Lịch sử các commit chính.}
\begin{tabular}{@{}lp{3cm}p{6cm}@{}}
\toprule
\textbf{Commit} & \textbf{Ngày} & \textbf{Mô tả} \\
\midrule
\texttt{15e684e} & 30/01/2026 & Cross-platform config.py \\
\texttt{7aa8947} & 31/01/2026 & TensorFlow $\rightarrow$ PyTorch migration \\
\texttt{b36824c} & 01/02/2026 & All notebooks migrated + AUC fix \\
\bottomrule
\end{tabular}
\end{table}

\section{Đóng góp so với bản gốc}
\begin{enumerate}
  \item \textbf{Hiện đại hoá:} TensorFlow $\rightarrow$ PyTorch
  \item \textbf{Chuẩn hoá pipeline:} Tất cả notebooks dùng chung \texttt{data.ipynb}
  \item \textbf{Cross-platform:} Hoạt động trên Windows, macOS, Linux
  \item \textbf{Bug fixes:} AUC NaN, ReduceLROnPlateau verbose
  \item \textbf{Tài liệu:} \texttt{BAO\_CAO\_THAY\_DOI.md} chi tiết
  \item \textbf{Reproducibility:} Fixed seed, log versions
\end{enumerate}

% ============================================================
% CONCLUSION
% ============================================================
\chapter{Kết luận}
Bài báo \cite{jain2024} cung cấp một so sánh thực nghiệm hữu ích giữa \CNN, \ResNet\ và \ViT\ trên \Dataset.
Kết quả cho thấy:
\begin{itemize}
  \item \ResNet\ vẫn là baseline mạnh và ổn định
  \item \ViT\ from-scratch cạnh tranh nhưng không luôn vượt \ResNet
  \item Mô hình hybrid có thể đạt accuracy cao
\end{itemize}

\textbf{Đóng góp của nhóm:} Chúng tôi đã tái lập thành công codebase với các cải tiến quan trọng: migration sang PyTorch, chuẩn hoá pipeline, sửa lỗi metric, và tài liệu hoá đầy đủ. Các thay đổi này tạo nền tảng vững chắc cho nghiên cứu mở rộng.

% ============================================================
% REFERENCES
% ============================================================
\begin{thebibliography}{99}

\bibitem{jain2024}
A.~Jain, A.~Bhardwaj, K.~Murali, and I.~Surani,
\newblock ``A Comparative Study of CNN, ResNet, and Vision Transformers for Multi-Classification of Chest Diseases,''
\newblock arXiv:2406.00237, 2024.
\newblock \url{https://arxiv.org/abs/2406.00237}

\bibitem{aviralrepo}
Aviral-03,
\newblock ``ViT-Chest-Xray (GitHub repository),''
\newblock 2024.
\newblock \url{https://github.com/Aviral-03/ViT-Chest-Xray}

\bibitem{dosovitskiy2021}
A.~Dosovitskiy et~al.,
\newblock ``An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale,''
\newblock ICLR, 2021.
\newblock \url{https://arxiv.org/abs/2010.11929}

\bibitem{he2016}
K.~He, X.~Zhang, S.~Ren, and J.~Sun,
\newblock ``Deep Residual Learning for Image Recognition,''
\newblock CVPR, 2016.
\newblock \url{https://arxiv.org/abs/1512.03385}

\bibitem{wang2017}
X.~Wang et~al.,
\newblock ``ChestX-ray8: Hospital-scale Chest X-ray Database and Benchmarks,''
\newblock CVPR, 2017.
\newblock \url{https://arxiv.org/abs/1705.02315}

\bibitem{selvaraju2017}
R.~R. Selvaraju et~al.,
\newblock ``Grad-CAM: Visual Explanations From Deep Networks,''
\newblock ICCV, 2017.
\newblock \url{https://arxiv.org/abs/1610.02391}

\end{thebibliography}

\end{document}
