{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vision Transformer (Pre - Trained)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ViT-ResNet - Pre-trained Vision Transformer using timm library\n",
    "import os\n",
    "import warnings\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import timm\n",
    "\n",
    "from torch.optim import AdamW\n",
    "from sklearn.metrics import roc_auc_score, roc_curve, auc\n",
    "from itertools import cycle\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run data.ipynb to get data loaders\n",
    "%run data.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Device configuration\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "num_classes = len(parser.labels)\n",
    "batch_size = 16\n",
    "learning_rate = 1e-4\n",
    "num_epochs = 10\n",
    "\n",
    "print(f\"Number of classes: {num_classes}\")\n",
    "print(f\"Batch size: {batch_size}\")\n",
    "print(f\"Learning rate: {learning_rate}\")\n",
    "print(f\"Epochs: {num_epochs}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Pre-trained ViT model using timm\n",
    "model = timm.create_model('vit_base_patch16_224', pretrained=True)\n",
    "\n",
    "# Modify classification head for our task\n",
    "model.head = nn.Linear(model.head.in_features, num_classes)\n",
    "model = model.to(device)\n",
    "\n",
    "# Loss and optimizer\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = AdamW(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# Print model info\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(f\"Model: vit_base_patch16_224 (pretrained)\")\n",
    "print(f\"Total parameters: {total_params:,}\")\n",
    "print(f\"Trainable parameters: {trainable_params:,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training function with AUC fix\n",
    "def train_model(model, train_loader, val_loader, criterion, optimizer, num_epochs=10, save_path='files/vit_pretrained_best.pth'):\n",
    "    \"\"\"Train pre-trained ViT model\"\"\"\n",
    "    history = {\n",
    "        'train_loss': [], 'val_loss': [],\n",
    "        'train_acc': [], 'val_acc': [],\n",
    "        'train_auc': [], 'val_auc': []\n",
    "    }\n",
    "    \n",
    "    best_val_loss = float('inf')\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        # Training phase\n",
    "        model.train()\n",
    "        train_loss = 0.0\n",
    "        train_correct = 0\n",
    "        train_total = 0\n",
    "        all_train_targets = []\n",
    "        all_train_outputs = []\n",
    "        \n",
    "        train_pbar = tqdm(train_loader, desc=f'Epoch {epoch+1}/{num_epochs} [Train]')\n",
    "        for images, labels in train_pbar:\n",
    "            images, labels = images.to(device), labels.to(device).float()\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            train_loss += loss.item() * images.size(0)\n",
    "            preds = (torch.sigmoid(outputs) > 0.5).float()\n",
    "            train_correct += (preds == labels).sum().item()\n",
    "            train_total += labels.numel()\n",
    "            \n",
    "            all_train_targets.append(labels.cpu().numpy())\n",
    "            all_train_outputs.append(torch.sigmoid(outputs).detach().cpu().numpy())\n",
    "            \n",
    "            train_pbar.set_postfix({'loss': loss.item()})\n",
    "        \n",
    "        # Calculate training metrics\n",
    "        epoch_train_loss = train_loss / len(train_loader.dataset)\n",
    "        epoch_train_acc = train_correct / train_total * 100\n",
    "        \n",
    "        # AUC calculation with valid classes check\n",
    "        all_train_targets = np.vstack(all_train_targets)\n",
    "        all_train_outputs = np.vstack(all_train_outputs)\n",
    "        try:\n",
    "            valid_classes = [i for i in range(all_train_targets.shape[1]) \n",
    "                           if len(np.unique(all_train_targets[:, i])) > 1]\n",
    "            if len(valid_classes) > 0:\n",
    "                epoch_train_auc = roc_auc_score(\n",
    "                    all_train_targets[:, valid_classes],\n",
    "                    all_train_outputs[:, valid_classes],\n",
    "                    average='macro'\n",
    "                )\n",
    "            else:\n",
    "                epoch_train_auc = 0.0\n",
    "        except ValueError:\n",
    "            epoch_train_auc = 0.0\n",
    "        \n",
    "        history['train_loss'].append(epoch_train_loss)\n",
    "        history['train_acc'].append(epoch_train_acc)\n",
    "        history['train_auc'].append(epoch_train_auc)\n",
    "        \n",
    "        # Validation phase\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        val_correct = 0\n",
    "        val_total = 0\n",
    "        all_val_targets = []\n",
    "        all_val_outputs = []\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for images, labels in val_loader:\n",
    "                images, labels = images.to(device), labels.to(device).float()\n",
    "                outputs = model(images)\n",
    "                loss = criterion(outputs, labels)\n",
    "                \n",
    "                val_loss += loss.item() * images.size(0)\n",
    "                preds = (torch.sigmoid(outputs) > 0.5).float()\n",
    "                val_correct += (preds == labels).sum().item()\n",
    "                val_total += labels.numel()\n",
    "                \n",
    "                all_val_targets.append(labels.cpu().numpy())\n",
    "                all_val_outputs.append(torch.sigmoid(outputs).cpu().numpy())\n",
    "        \n",
    "        # Calculate validation metrics\n",
    "        epoch_val_loss = val_loss / len(val_loader.dataset)\n",
    "        epoch_val_acc = val_correct / val_total * 100\n",
    "        \n",
    "        all_val_targets = np.vstack(all_val_targets)\n",
    "        all_val_outputs = np.vstack(all_val_outputs)\n",
    "        try:\n",
    "            valid_classes = [i for i in range(all_val_targets.shape[1]) \n",
    "                           if len(np.unique(all_val_targets[:, i])) > 1]\n",
    "            if len(valid_classes) > 0:\n",
    "                epoch_val_auc = roc_auc_score(\n",
    "                    all_val_targets[:, valid_classes],\n",
    "                    all_val_outputs[:, valid_classes],\n",
    "                    average='macro'\n",
    "                )\n",
    "            else:\n",
    "                epoch_val_auc = 0.0\n",
    "        except ValueError:\n",
    "            epoch_val_auc = 0.0\n",
    "        \n",
    "        history['val_loss'].append(epoch_val_loss)\n",
    "        history['val_acc'].append(epoch_val_acc)\n",
    "        history['val_auc'].append(epoch_val_auc)\n",
    "        \n",
    "        print(f'Epoch {epoch+1}/{num_epochs}:')\n",
    "        print(f'  Train - Loss: {epoch_train_loss:.4f}, Acc: {epoch_train_acc:.2f}%, AUC: {epoch_train_auc:.4f}')\n",
    "        print(f'  Val   - Loss: {epoch_val_loss:.4f}, Acc: {epoch_val_acc:.2f}%, AUC: {epoch_val_auc:.4f}')\n",
    "        \n",
    "        # Save best model\n",
    "        if epoch_val_loss < best_val_loss:\n",
    "            best_val_loss = epoch_val_loss\n",
    "            torch.save(model.state_dict(), save_path)\n",
    "            print(f'  >> Saved best model with val_loss: {best_val_loss:.4f}')\n",
    "    \n",
    "    return history\n",
    "\n",
    "print(\"Training function defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "history = train_model(model, train_loader, val_loader, criterion, optimizer, num_epochs=num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate on test set\n",
    "def evaluate_model(model, test_loader, criterion):\n",
    "    \"\"\"Evaluate model on test set\"\"\"\n",
    "    model.eval()\n",
    "    test_loss = 0.0\n",
    "    test_correct = 0\n",
    "    test_total = 0\n",
    "    all_targets = []\n",
    "    all_outputs = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for images, labels in tqdm(test_loader, desc='Testing'):\n",
    "            images, labels = images.to(device), labels.to(device).float()\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            test_loss += loss.item() * images.size(0)\n",
    "            preds = (torch.sigmoid(outputs) > 0.5).float()\n",
    "            test_correct += (preds == labels).sum().item()\n",
    "            test_total += labels.numel()\n",
    "            \n",
    "            all_targets.append(labels.cpu().numpy())\n",
    "            all_outputs.append(torch.sigmoid(outputs).cpu().numpy())\n",
    "    \n",
    "    test_loss = test_loss / len(test_loader.dataset)\n",
    "    test_acc = test_correct / test_total * 100\n",
    "    \n",
    "    all_targets = np.vstack(all_targets)\n",
    "    all_outputs = np.vstack(all_outputs)\n",
    "    \n",
    "    try:\n",
    "        valid_classes = [i for i in range(all_targets.shape[1]) \n",
    "                       if len(np.unique(all_targets[:, i])) > 1]\n",
    "        if len(valid_classes) > 0:\n",
    "            test_auc = roc_auc_score(\n",
    "                all_targets[:, valid_classes],\n",
    "                all_outputs[:, valid_classes],\n",
    "                average='macro'\n",
    "            )\n",
    "        else:\n",
    "            test_auc = 0.0\n",
    "    except ValueError:\n",
    "        test_auc = 0.0\n",
    "    \n",
    "    print(f\"\\nTest Results (Pre-trained ViT):\")\n",
    "    print(f\"  Loss: {test_loss:.4f}\")\n",
    "    print(f\"  Accuracy: {test_acc:.2f}%\")\n",
    "    print(f\"  AUC: {test_auc:.4f}\")\n",
    "    \n",
    "    return test_loss, test_acc, test_auc\n",
    "\n",
    "test_loss, test_acc, test_auc = evaluate_model(model, test_loader, criterion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training history\n",
    "def plot_training_history(history):\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(15, 4))\n",
    "    \n",
    "    # Loss\n",
    "    axes[0].plot(history['train_loss'], label='Train Loss')\n",
    "    axes[0].plot(history['val_loss'], label='Val Loss')\n",
    "    axes[0].set_xlabel('Epoch')\n",
    "    axes[0].set_ylabel('Loss')\n",
    "    axes[0].set_title('Pre-trained ViT: Loss')\n",
    "    axes[0].legend()\n",
    "    axes[0].grid(True)\n",
    "    \n",
    "    # Accuracy\n",
    "    axes[1].plot(history['train_acc'], label='Train Acc')\n",
    "    axes[1].plot(history['val_acc'], label='Val Acc')\n",
    "    axes[1].set_xlabel('Epoch')\n",
    "    axes[1].set_ylabel('Accuracy (%)')\n",
    "    axes[1].set_title('Pre-trained ViT: Accuracy')\n",
    "    axes[1].legend()\n",
    "    axes[1].grid(True)\n",
    "    \n",
    "    # AUC\n",
    "    axes[2].plot(history['train_auc'], label='Train AUC')\n",
    "    axes[2].plot(history['val_auc'], label='Val AUC')\n",
    "    axes[2].set_xlabel('Epoch')\n",
    "    axes[2].set_ylabel('AUC')\n",
    "    axes[2].set_title('Pre-trained ViT: AUC')\n",
    "    axes[2].legend()\n",
    "    axes[2].grid(True)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('files/vit_pretrained_training.png', dpi=150)\n",
    "    plt.show()\n",
    "\n",
    "plot_training_history(history)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
