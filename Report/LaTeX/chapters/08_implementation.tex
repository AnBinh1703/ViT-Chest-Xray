% ============================================================
% CHAPTER 8: PYTORCH IMPLEMENTATION
% ============================================================
\chapter{PyTorch Implementation Details}

\section{Migration Overview}

\subsection{From TensorFlow to PyTorch}

\begin{tcolorbox}[colback=blue!5!white,colframe=blue!75!black,title=Migration Summary]
\textbf{Original Paper:} TensorFlow/Keras implementation

\textbf{Our Contribution:} Complete PyTorch reimplementation with:
\begin{itemize}
    \item All 5 model architectures (CNN, ResNet, ViT-v1, ViT-v2, ViT-ResNet)
    \item Bug fixes (AUC NaN issue)
    \item Code cleanup and documentation
    \item Consistent coding style
\end{itemize}
\end{tcolorbox}

\subsection{Framework Comparison}

\begin{table}[H]
\centering
\caption{TensorFlow/Keras vs PyTorch Comparison}
\begin{tabular}{lcc}
\toprule
\textbf{Aspect} & \textbf{TensorFlow/Keras} & \textbf{PyTorch} \\
\midrule
Paradigm & Define-and-run & Define-by-run \\
Debugging & Harder (graph mode) & Easier (eager execution) \\
Model definition & Sequential/Functional & nn.Module class \\
Training loop & model.fit() & Manual loop \\
Flexibility & Less flexible & More flexible \\
Research use & Moderate & High \\
\bottomrule
\end{tabular}
\end{table}

\section{Key Differences in Implementation}

\subsection{Model Definition}

\subsubsection{Keras Version (Original)}

\begin{lstlisting}[caption={CNN in Keras (from paper)}]
model = Sequential([
    Conv2D(32, (3, 3), activation='relu', input_shape=(224, 224, 3)),
    MaxPooling2D(pool_size=(2, 2)),
    Conv2D(64, (3, 3), activation='relu'),
    MaxPooling2D(pool_size=(2, 2)),
    Flatten(),
    Dense(512, activation='relu'),
    Dropout(0.5),
    Dense(15, activation='softmax')
])
\end{lstlisting}

\subsubsection{PyTorch Version (Our Implementation)}

\begin{lstlisting}[caption={CNN in PyTorch}]
class CNNClassifier(nn.Module):
    def __init__(self, num_classes=15):
        super(CNNClassifier, self).__init__()
        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, padding=1)
        self.pool = nn.MaxPool2d(2, 2)
        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)
        self.fc1 = nn.Linear(64 * 56 * 56, 512)
        self.dropout = nn.Dropout(0.5)
        self.fc2 = nn.Linear(512, num_classes)
    
    def forward(self, x):
        x = self.pool(F.relu(self.conv1(x)))
        x = self.pool(F.relu(self.conv2(x)))
        x = x.view(x.size(0), -1)
        x = self.dropout(F.relu(self.fc1(x)))
        x = self.fc2(x)
        return x
\end{lstlisting}

\subsection{Training Loop}

\subsubsection{Keras Version}

\begin{lstlisting}[caption={Training in Keras}]
model.compile(
    optimizer='adam',
    loss='categorical_crossentropy',
    metrics=['accuracy']
)
history = model.fit(
    train_data,
    epochs=30,
    validation_data=val_data
)
\end{lstlisting}

\subsubsection{PyTorch Version}

\begin{lstlisting}[caption={Training in PyTorch}]
criterion = nn.BCEWithLogitsLoss()
optimizer = optim.Adam(model.parameters(), lr=1e-4)

for epoch in range(num_epochs):
    model.train()
    for images, labels in train_loader:
        images, labels = images.to(device), labels.to(device)
        
        optimizer.zero_grad()
        outputs = model(images)
        loss = criterion(outputs, labels)
        loss.backward()
        optimizer.step()
    
    # Validation
    model.eval()
    with torch.no_grad():
        # ... validation logic
\end{lstlisting}

\section{Critical Bug Fix: AUC NaN Issue}

\subsection{Problem Description}

\begin{tcolorbox}[colback=red!5!white,colframe=red!75!black,title=Bug: AUC Returns NaN]
\textbf{Symptom:}
\begin{lstlisting}[style=plain]
Val AUC: nan
\end{lstlisting}

\textbf{Root Cause:}
\begin{itemize}
    \item sklearn's \texttt{roc\_auc\_score} requires both classes (0 and 1) present
    \item With small batches or imbalanced data, some classes may have only 0s or only 1s
    \item AUC undefined for single-class data â†’ returns NaN
\end{itemize}
\end{tcolorbox}

\subsection{Solution}

\begin{lstlisting}[caption={AUC Fix Implementation}]
def compute_auc_safe(y_true, y_pred):
    """
    Compute AUC-ROC safely, handling classes with only one label.
    
    Args:
        y_true: Ground truth labels (N, num_classes)
        y_pred: Predicted probabilities (N, num_classes)
    
    Returns:
        Macro AUC over valid classes, or 0.0 if no valid classes
    """
    num_classes = y_true.shape[1]
    valid_classes = []
    
    # Check each class for presence of both labels
    for c in range(num_classes):
        unique_labels = np.unique(y_true[:, c])
        # Need both 0 and 1 to compute AUC
        if len(unique_labels) > 1:
            valid_classes.append(c)
    
    if len(valid_classes) == 0:
        print("Warning: No valid classes for AUC computation")
        return 0.0
    
    # Compute AUC only for valid classes
    auc = roc_auc_score(
        y_true[:, valid_classes],
        y_pred[:, valid_classes],
        average='macro'
    )
    
    return auc
\end{lstlisting}

\subsection{Integration in Training Loop}

\begin{lstlisting}[caption={Using safe AUC in validation}]
# Collect all predictions
all_preds = []
all_labels = []

model.eval()
with torch.no_grad():
    for images, labels in val_loader:
        images = images.to(device)
        outputs = model(images)
        probs = torch.sigmoid(outputs)
        
        all_preds.append(probs.cpu().numpy())
        all_labels.append(labels.numpy())

# Concatenate batches
all_preds = np.concatenate(all_preds, axis=0)
all_labels = np.concatenate(all_labels, axis=0)

# Compute AUC safely
val_auc = compute_auc_safe(all_labels, all_preds)
print(f"Validation AUC: {val_auc:.4f}")
\end{lstlisting}

\section{Learning Rate Scheduler Fix}

\subsection{ReduceLROnPlateau Verbose Issue}

\begin{tcolorbox}[colback=orange!5!white,colframe=orange!75!black,title=Deprecation Warning]
\textbf{PyTorch 2.x Change:}
\begin{lstlisting}[style=plain]
# Old (deprecated):
scheduler = ReduceLROnPlateau(optimizer, verbose=True)

# New (correct):
scheduler = ReduceLROnPlateau(optimizer)
# Use callback or manual logging instead
\end{lstlisting}
\end{tcolorbox}

\subsection{Correct Implementation}

\begin{lstlisting}[caption={Learning Rate Scheduler Setup}]
scheduler = optim.lr_scheduler.ReduceLROnPlateau(
    optimizer,
    mode='min',           # Reduce when metric stops decreasing
    factor=0.1,           # Multiply LR by 0.1
    patience=3,           # Wait 3 epochs before reducing
    min_lr=1e-7           # Minimum LR
)

# In training loop:
for epoch in range(num_epochs):
    # ... training ...
    
    val_loss = validate(model, val_loader)
    scheduler.step(val_loss)
    
    # Manual logging
    current_lr = optimizer.param_groups[0]['lr']
    print(f"Epoch {epoch}: LR = {current_lr}")
\end{lstlisting}

\section{Data Loading Pipeline}

\subsection{PyTorch DataLoader}

\begin{lstlisting}[caption={Custom Dataset and DataLoader}]
class ChestXrayDataset(Dataset):
    def __init__(self, dataframe, images_path, labels, transform=None):
        self.dataframe = dataframe.reset_index(drop=True)
        self.images_path = images_path
        self.labels = labels
        self.transform = transform
    
    def __len__(self):
        return len(self.dataframe)
    
    def __getitem__(self, idx):
        # Get image path
        img_name = self.dataframe.iloc[idx]['Image Index']
        img_path = os.path.join(self.images_path, img_name)
        
        # Load and convert to RGB
        image = Image.open(img_path).convert('RGB')
        
        # Apply transforms
        if self.transform:
            image = self.transform(image)
        
        # Get multi-label target
        label = torch.tensor(
            self.dataframe.iloc[idx][self.labels].values.astype(float),
            dtype=torch.float32
        )
        
        return image, label

# Create DataLoaders
train_dataset = ChestXrayDataset(train_df, img_path, labels, train_transform)
train_loader = DataLoader(
    train_dataset,
    batch_size=32,
    shuffle=True,
    num_workers=4,
    pin_memory=True  # Faster GPU transfer
)
\end{lstlisting}

\subsection{Data Transforms}

\begin{lstlisting}[caption={PyTorch transforms for training and validation}]
from torchvision import transforms

train_transform = transforms.Compose([
    transforms.Resize((224, 224)),
    transforms.RandomHorizontalFlip(p=0.5),
    transforms.RandomRotation(degrees=5),
    transforms.ColorJitter(brightness=0.1, contrast=0.1),
    transforms.ToTensor(),
    transforms.Normalize(
        mean=[0.485, 0.456, 0.406],
        std=[0.229, 0.224, 0.225]
    )
])

val_transform = transforms.Compose([
    transforms.Resize((224, 224)),
    transforms.ToTensor(),
    transforms.Normalize(
        mean=[0.485, 0.456, 0.406],
        std=[0.229, 0.224, 0.225]
    )
])
\end{lstlisting}

\section{GPU Acceleration}

\subsection{Device Setup}

\begin{lstlisting}[caption={GPU/CPU device selection}]
# Check CUDA availability
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
print(f"Using device: {device}")

# Move model to device
model = model.to(device)

# In training loop
for images, labels in train_loader:
    images = images.to(device)
    labels = labels.to(device)
    # ... rest of training
\end{lstlisting}

\subsection{Mixed Precision Training (Optional)}

\begin{lstlisting}[caption={Mixed precision for faster training}]
from torch.cuda.amp import autocast, GradScaler

scaler = GradScaler()

for images, labels in train_loader:
    images, labels = images.to(device), labels.to(device)
    
    optimizer.zero_grad()
    
    # Forward pass with mixed precision
    with autocast():
        outputs = model(images)
        loss = criterion(outputs, labels)
    
    # Backward pass with scaling
    scaler.scale(loss).backward()
    scaler.step(optimizer)
    scaler.update()
\end{lstlisting}

\section{Model Checkpointing}

\begin{lstlisting}[caption={Saving and loading model checkpoints}]
# Save checkpoint
def save_checkpoint(model, optimizer, epoch, loss, path):
    torch.save({
        'epoch': epoch,
        'model_state_dict': model.state_dict(),
        'optimizer_state_dict': optimizer.state_dict(),
        'loss': loss,
    }, path)

# Load checkpoint
def load_checkpoint(model, optimizer, path):
    checkpoint = torch.load(path)
    model.load_state_dict(checkpoint['model_state_dict'])
    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])
    epoch = checkpoint['epoch']
    loss = checkpoint['loss']
    return model, optimizer, epoch, loss

# Save best model
if val_auc > best_auc:
    best_auc = val_auc
    save_checkpoint(model, optimizer, epoch, val_loss, 'best_model.pth')
\end{lstlisting}

\section{Complete Training Script}

\begin{lstlisting}[caption={Complete training function}]
def train_model(
    model,
    train_loader,
    val_loader,
    num_epochs=30,
    learning_rate=1e-4,
    device='cuda'
):
    """
    Complete training pipeline for chest x-ray classification.
    """
    model = model.to(device)
    criterion = nn.BCEWithLogitsLoss()
    optimizer = optim.Adam(model.parameters(), lr=learning_rate)
    scheduler = optim.lr_scheduler.ReduceLROnPlateau(
        optimizer, mode='min', patience=3, factor=0.1
    )
    
    best_auc = 0.0
    history = {'train_loss': [], 'val_loss': [], 'val_auc': []}
    
    for epoch in range(num_epochs):
        # ===== Training Phase =====
        model.train()
        train_loss = 0.0
        
        for images, labels in train_loader:
            images = images.to(device)
            labels = labels.to(device)
            
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            
            train_loss += loss.item()
        
        train_loss /= len(train_loader)
        
        # ===== Validation Phase =====
        model.eval()
        val_loss = 0.0
        all_preds, all_labels = [], []
        
        with torch.no_grad():
            for images, labels in val_loader:
                images = images.to(device)
                labels = labels.to(device)
                
                outputs = model(images)
                loss = criterion(outputs, labels)
                val_loss += loss.item()
                
                probs = torch.sigmoid(outputs)
                all_preds.append(probs.cpu().numpy())
                all_labels.append(labels.cpu().numpy())
        
        val_loss /= len(val_loader)
        
        # Compute AUC (with fix)
        all_preds = np.concatenate(all_preds)
        all_labels = np.concatenate(all_labels)
        val_auc = compute_auc_safe(all_labels, all_preds)
        
        # Update scheduler
        scheduler.step(val_loss)
        
        # Save best model
        if val_auc > best_auc:
            best_auc = val_auc
            torch.save(model.state_dict(), 'best_model.pth')
        
        # Log progress
        print(f"Epoch {epoch+1}/{num_epochs}")
        print(f"  Train Loss: {train_loss:.4f}")
        print(f"  Val Loss: {val_loss:.4f}")
        print(f"  Val AUC: {val_auc:.4f}")
        print(f"  LR: {optimizer.param_groups[0]['lr']:.6f}")
        
        # Store history
        history['train_loss'].append(train_loss)
        history['val_loss'].append(val_loss)
        history['val_auc'].append(val_auc)
    
    return model, history
\end{lstlisting}

\section{Repository Structure}

\begin{lstlisting}[style=plain,caption={Project structure}]
ViT-Chest-Xray/
|-- Project/
|   |-- cnn.ipynb           # CNN implementation
|   |-- resnet.ipynb        # ResNet-34 implementation
|   |-- ViT-v1.ipynb        # Vision Transformer v1
|   |-- ViT-v2.ipynb        # Vision Transformer v2
|   |-- ViT-ResNet.ipynb    # Hybrid ViT-ResNet
|   |-- data.ipynb          # Data preprocessing
|   |-- data_download.ipynb # Dataset download
|   |-- config.py           # Configuration
|   `-- data/               # Dataset folder
|-- Report/
|   `-- LaTeX/              # This documentation
|-- requirements.txt        # Dependencies
`-- README.md              # Project readme
\end{lstlisting}
