{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vision Transformer - V2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "import random\n",
    "import math\n",
    "import warnings\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import tensorflow as tf\n",
    "import torch\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "from tensorflow.keras.applications.inception_resnet_v2 import InceptionResNetV2\n",
    "\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run data.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "else:\n",
    "    if gpus:\n",
    "        device = '/GPU:0'  # Use the first GPU if available\n",
    "    else:\n",
    "        device = '/CPU:0'  # Use CPU if no GPU is available\n",
    "print(\"Using device:\", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mlp(x, hidden_units, dropout_rate, regularizer_rate=0.01):\n",
    "    for units in hidden_units:\n",
    "        x = Dense(units, activation=tf.nn.gelu, kernel_regularizer=l2(regularizer_rate))(x)\n",
    "        x = Dropout(dropout_rate)(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers\n",
    "\n",
    "class Patches(layers.Layer):\n",
    "    def __init__(self, patch_size):\n",
    "        super(Patches, self).__init__()\n",
    "        self.patch_size = patch_size\n",
    "\n",
    "    def call(self, images):\n",
    "        batch_size = tf.shape(images)[0]\n",
    "        patches = tf.image.extract_patches(\n",
    "            images=images,\n",
    "            sizes=[1, self.patch_size, self.patch_size, 1],\n",
    "            strides=[1, self.patch_size, self.patch_size, 1],\n",
    "            rates=[1, 1, 1, 1],\n",
    "            padding='VALID',\n",
    "        )\n",
    "        patch_dims = patches.shape[-1]\n",
    "        patches = tf.reshape(patches, [batch_size, -1, patch_dims])\n",
    "        return patches\n",
    "\n",
    "    def get_config(self):\n",
    "        config = super(Patches, self).get_config()\n",
    "        config.update({\"patch_size\": self.patch_size})\n",
    "        return config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for image_batch, label_batch in train_generator:\n",
    "    image = image_batch[0] \n",
    "    break \n",
    "\n",
    "image_size = 224\n",
    "patch_size = 32  \n",
    "num_patches = (image_size // patch_size) ** 2\n",
    "\n",
    "plt.figure(figsize=(4, 4))\n",
    "plt.imshow(image)\n",
    "plt.axis(\"off\")\n",
    "plt.show()\n",
    "\n",
    "image_tensor = tf.expand_dims(image, 0) \n",
    "\n",
    "patches_layer = Patches(patch_size)\n",
    "patches = patches_layer(image_tensor)\n",
    "\n",
    "patches_numpy = patches.numpy()\n",
    "if np.max(patches_numpy) <= 1.0:\n",
    "    patches_numpy *= 255  \n",
    "patches_numpy = patches_numpy.astype('uint8') \n",
    "\n",
    "n = int(np.sqrt(num_patches))\n",
    "plt.figure(figsize=(4, 4))\n",
    "for i in range(n * n):\n",
    "    ax = plt.subplot(n, n, i + 1)\n",
    "    patch_img = patches_numpy[0, i].reshape(patch_size, patch_size, 3)\n",
    "    plt.imshow(patch_img)\n",
    "    plt.axis(\"off\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PatchEncoder(layers.Layer):\n",
    "    def __init__(self, num_patches, projection_dim):\n",
    "        super().__init__()\n",
    "        self.num_patches = num_patches\n",
    "        self.projection = layers.Dense(units=projection_dim)\n",
    "        self.position_embedding = layers.Embedding(\n",
    "            input_dim=num_patches, output_dim=projection_dim\n",
    "        )\n",
    "\n",
    "    def call(self, patch):\n",
    "        positions = ops.expand_dims(\n",
    "            ops.arange(start=0, stop=self.num_patches, step=1), axis=0\n",
    "        )\n",
    "        projected_patches = self.projection(patch)\n",
    "        encoded = projected_patches + self.position_embedding(positions)\n",
    "        return encoded\n",
    "\n",
    "    def get_config(self):\n",
    "        config = super().get_config()\n",
    "        config.update({\"num_patches\": self.num_patches})\n",
    "        return config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_patches = (image_size // patch_size) ** 2\n",
    "projection_dim = 64\n",
    "\n",
    "patch_encoder = PatchEncoder(num_patches=num_patches, projection_dim=projection_dim)\n",
    "\n",
    "encoded_patches = patch_encoder(patches)\n",
    "\n",
    "input_shape = (224, 224, 3)  \n",
    "patch_size = 32             \n",
    "num_patches = (224 // patch_size) ** 2  \n",
    "projection_dim = 64          \n",
    "num_heads = 4                \n",
    "transformer_units = [\n",
    "    projection_dim * 2,      \n",
    "    projection_dim,\n",
    "]\n",
    "transformer_layers = 8       \n",
    "mlp_head_units = [2048, 1024]  \n",
    "num_classes = len(parser.labels)  \n",
    "test_datagen = ImageDataGenerator(rescale=1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "learning_rate = 1e-4\n",
    "weight_decay = 1e-5\n",
    "num_epochs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Early stopping callback\n",
    "early_stopping_callback = EarlyStopping(\n",
    "    monitor=\"val_accuracy\",\n",
    "    patience=3,\n",
    "    restore_best_weights=False,\n",
    ")\n",
    "\n",
    "# Choose an optimizer\n",
    "optimizers = {\n",
    "    \"adam\": keras.optimizers.Adam(learning_rate=learning_rate),\n",
    "    \"adamw\": keras.optimizers.AdamW(learning_rate=learning_rate, weight_decay=weight_decay),\n",
    "    \"sgd\": keras.optimizers.SGD(learning_rate=0.01, momentum=0.9, nesterov=True, weight_decay=weight_decay),\n",
    "    \"sgd_momentum\": keras.optimizers.SGD(learning_rate=learning_rate, momentum=0.9),\n",
    "    \"adagrad\": keras.optimizers.Adagrad(learning_rate=learning_rate),\n",
    "    \"rmsprop\": keras.optimizers.RMSprop(learning_rate=learning_rate)\n",
    "}\n",
    "\n",
    "optimizer = optimizers[\"sgd\"]\n",
    "lr_scheduler = ReduceLROnPlateau(\n",
    "    monitor='val_loss',\n",
    "    factor=0.1,\n",
    "    patience=5,\n",
    "    min_lr=1e-6,\n",
    "    verbose=1\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_vit_classifier():\n",
    "    inputs = Input(shape=input_shape)\n",
    "    patches = Patches(patch_size)(inputs)\n",
    "    encoded_patches = PatchEncoder(num_patches, projection_dim)(patches)\n",
    "    for _ in range(transformer_layers):\n",
    "        x1 = LayerNormalization(epsilon=1e-6)(encoded_patches)\n",
    "        attention_output = MultiHeadAttention(\n",
    "            num_heads=num_heads, key_dim=projection_dim, dropout=0.1\n",
    "        )(x1, x1)\n",
    "        x2 = Add()([attention_output, encoded_patches])\n",
    "        x3 = LayerNormalization(epsilon=1e-6)(x2)\n",
    "        x3 = mlp(x3, transformer_units, dropout_rate=0.1, regularizer_rate=0.01)\n",
    "        encoded_patches = Add()([x3, x2])\n",
    "    representation = LayerNormalization(epsilon=1e-6)(encoded_patches)\n",
    "    representation = Flatten()(representation)\n",
    "    features = mlp(representation, mlp_head_units, dropout_rate=0.5, regularizer_rate=0.01)\n",
    "    logits = Dense(num_classes, activation='sigmoid')(features)\n",
    "    model = Model(inputs=inputs, outputs=logits)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_experiment(model):\n",
    "    model.compile(\n",
    "    optimizer=optimizer,\n",
    "    loss='binary_crossentropy',\n",
    "    metrics=[\n",
    "        keras.metrics.BinaryAccuracy(name=\"accuracy\"),\n",
    "        keras.metrics.AUC(name=\"auc\"),\n",
    "    ]\n",
    "    )\n",
    "\n",
    "    history = model.fit(\n",
    "        train_generator,\n",
    "        epochs=num_epochs,\n",
    "        validation_data=validation_generator,\n",
    "        callbacks=[ModelCheckpoint(os.path.join(\"files\", \"model.keras\"), monitor='val_loss', verbose=1, save_best_only=True), \n",
    "                   early_stopping_callback, lr_scheduler],\n",
    "    )\n",
    "\n",
    "\n",
    "    return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vit_classifier = create_vit_classifier()\n",
    "history = run_experiment(vit_classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_combined_history(history):\n",
    "    plt.figure(figsize=(12, 5))\n",
    "\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(history.history['loss'], label='Train Loss')\n",
    "    plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "    plt.title('Train and Validation Loss', fontsize=14)\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "\n",
    "    plt.subplot(1, 2, 2) \n",
    "    plt.plot(history.history['accuracy'], label='Train Accuracy')\n",
    "    plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "    plt.title('Train and Validation Accuracy', fontsize=14)\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "\n",
    "    # plt.savefig('combined_history.png')\n",
    "    plt.show()\n",
    "\n",
    "plot_combined_history(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_generator.reset()\n",
    "steps = int(np.ceil(len(test_generator.filenames) / test_generator.batch_size))\n",
    "predictions = vit_classifier.predict(test_generator, steps=steps, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss, test_accuracy, test_auc = vit_classifier.evaluate(test_generator, steps=len(test_generator), verbose=0)\n",
    "print(\"Test accuracy: {:.2f}%\".format(test_accuracy * 100))\n",
    "print(\"Test AUC: {:.2f}\".format(test_auc))\n",
    "print(\"Test loss: {:.2f}\".format(loss))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_roc_curves(y_true, y_pred, num_classes, class_labels):\n",
    "    # Compute ROC curve and ROC area for each class\n",
    "    fpr = dict()\n",
    "    tpr = dict()\n",
    "    roc_auc = dict()\n",
    "    for i in range(num_classes):\n",
    "        fpr[i], tpr[i], _ = roc_curve(y_true[:, i], y_pred[:, i])\n",
    "        roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "\n",
    "    # Plot all ROC curves\n",
    "    plt.figure(figsize=(8, 8))\n",
    "    colors = cycle(['blue', 'red', 'green', 'orange', 'black', 'purple', 'cyan', 'magenta', 'yellow', 'lime'])\n",
    "    for i, color in zip(range(num_classes), colors):\n",
    "        plt.plot(fpr[i], tpr[i], color=color, lw=2,\n",
    "                 label='ROC curve of class {0} (area = {1:0.2f})'.format(class_labels[i], roc_auc[i]))\n",
    "\n",
    "    plt.plot([0, 1], [0, 1], 'k--', lw=2)\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('Receiver Operating Characteristic for Multi-Label Classification')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.savefig(\"roc_curveV2.png\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "\n",
    "mlb = MultiLabelBinarizer(classes=parser.labels)\n",
    "y_true = mlb.fit_transform(val['Label'])\n",
    "if y_true.shape[0] > predictions.shape[0]:\n",
    "    y_true = y_true[:predictions.shape[0], :]\n",
    "\n",
    "print(\"Shape of y_true:\", y_true.shape)\n",
    "print(\"Shape of predictions:\", predictions.shape)\n",
    "\n",
    "plot_roc_curves(y_true, predictions, num_classes=len(parser.labels), class_labels=parser.labels)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
